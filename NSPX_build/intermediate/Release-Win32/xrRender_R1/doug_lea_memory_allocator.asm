; Listing generated by Microsoft (R) Optimizing Compiler Version 19.29.30146.0 

	TITLE	i:\vitalya\mine\nsprojectx\nspx_build\intermediate\release-win32\xrrender_r1\doug_lea_memory_allocator.obj
	.686P
	.XMM
	include listing.inc
	.model	flat

INCLUDELIB OLDNAMES

PUBLIC	??_C@_0BK@NOJBAIDO@max?5system?5bytes?5?$DN?5?$CF10lu?6@ ; `string'
PUBLIC	??_C@_0BK@HGDMIJJL@system?5bytes?5?5?5?5?5?$DN?5?$CF10lu?6@ ; `string'
PUBLIC	??_C@_0BK@GOGELADF@in?5use?5bytes?5?5?5?5?5?$DN?5?$CF10lu?6@ ; `string'
EXTRN	__imp__VirtualQuery@12:PROC
EXTRN	__imp__GetSystemInfo@4:PROC
EXTRN	__imp____stdio_common_vfprintf:PROC
EXTRN	__imp____acrt_iob_func:PROC
EXTRN	__imp__VirtualAlloc@16:PROC
EXTRN	__imp__VirtualFree@12:PROC
EXTRN	__imp__abort:PROC
;	COMDAT ??_C@_0BK@GOGELADF@in?5use?5bytes?5?5?5?5?5?$DN?5?$CF10lu?6@
CONST	SEGMENT
??_C@_0BK@GOGELADF@in?5use?5bytes?5?5?5?5?5?$DN?5?$CF10lu?6@ DB 'in use b'
	DB	'ytes     = %10lu', 0aH, 00H			; `string'
CONST	ENDS
;	COMDAT ??_C@_0BK@HGDMIJJL@system?5bytes?5?5?5?5?5?$DN?5?$CF10lu?6@
CONST	SEGMENT
??_C@_0BK@HGDMIJJL@system?5bytes?5?5?5?5?5?$DN?5?$CF10lu?6@ DB 'system by'
	DB	'tes     = %10lu', 0aH, 00H			; `string'
CONST	ENDS
;	COMDAT ??_C@_0BK@NOJBAIDO@max?5system?5bytes?5?$DN?5?$CF10lu?6@
CONST	SEGMENT
??_C@_0BK@NOJBAIDO@max?5system?5bytes?5?$DN?5?$CF10lu?6@ DB 'max system b'
	DB	'ytes = %10lu', 0aH, 00H			; `string'
PUBLIC	_dlmallinfo
PUBLIC	_dlfree
PUBLIC	_dlmalloc
PUBLIC	___local_stdio_printf_options
_mparams DB	018H DUP (?)
__gm_	DB	01c8H DUP (?)
COMM	?_OptionsStorage@?1??__local_stdio_printf_options@@9@9:QWORD							; `__local_stdio_printf_options'::`2'::_OptionsStorage
_DATA	ENDS
; Function compile flags: /Ogtpy
; File C:\Program Files (x86)\Windows Kits\10\Include\10.0.22000.0\ucrt\corecrt_stdio_config.h
;	COMDAT ___local_stdio_printf_options
_TEXT	SEGMENT
___local_stdio_printf_options PROC			; COMDAT

; 91   :         static unsigned __int64 _OptionsStorage;
; 92   :         return &_OptionsStorage;

	mov	eax, OFFSET ?_OptionsStorage@?1??__local_stdio_printf_options@@9@9 ; `__local_stdio_printf_options'::`2'::_OptionsStorage

; 93   :     }

	ret	0
___local_stdio_printf_options ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_win32mmap PROC
; _size$ = ecx

; 1321 :   void* ptr = VirtualAlloc(0, size, MEM_RESERVE|MEM_COMMIT, PAGE_READWRITE);

	push	4
	push	12288					; 00003000H
	push	ecx
	push	0
	call	DWORD PTR __imp__VirtualAlloc@16

; 1322 :   return (ptr != 0)? ptr: MFAIL;

	or	ecx, -1
	test	eax, eax
	cmovne	ecx, eax
	mov	eax, ecx

; 1323 : }

	ret	0
_win32mmap ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_win32direct_mmap PROC
; _size$ = ecx

; 1327 :   void* ptr = VirtualAlloc(0, size, MEM_RESERVE|MEM_COMMIT|MEM_TOP_DOWN,

	push	4
	push	1060864					; 00103000H
	push	ecx
	push	0
	call	DWORD PTR __imp__VirtualAlloc@16

; 1328 :                            PAGE_READWRITE);
; 1329 :   return (ptr != 0)? ptr: MFAIL;

	or	ecx, -1
	test	eax, eax
	cmovne	ecx, eax
	mov	eax, ecx

; 1330 : }

	ret	0
_win32direct_mmap ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_minfo$ = -28						; size = 28
_win32munmap PROC
; _ptr$ = ecx
; _size$ = edx

; 1333 : static int win32munmap(void* ptr, size_t size) {

	sub	esp, 28					; 0000001cH
	push	ebx
	push	ebp
	push	esi
	push	edi
	mov	edi, edx
	mov	esi, ecx

; 1334 :   MEMORY_BASIC_INFORMATION minfo;
; 1335 :   char* cptr = ptr;
; 1336 :   while (size) {

	test	edi, edi
	je	SHORT $LN3@win32munma
	mov	ebp, DWORD PTR __imp__VirtualQuery@12
	mov	ebx, DWORD PTR __imp__VirtualFree@12
	npad	5
$LL2@win32munma:

; 1337 :     if (VirtualQuery(cptr, &minfo, sizeof(minfo)) == 0)

	push	28					; 0000001cH
	lea	eax, DWORD PTR _minfo$[esp+48]
	push	eax
	push	esi
	call	ebp
	test	eax, eax
	je	SHORT $LN6@win32munma

; 1338 :       return -1;
; 1339 :     if (minfo.BaseAddress != cptr || minfo.AllocationBase != cptr ||
; 1340 :         minfo.State != MEM_COMMIT || minfo.RegionSize > size)

	cmp	DWORD PTR _minfo$[esp+44], esi
	jne	SHORT $LN6@win32munma
	cmp	DWORD PTR _minfo$[esp+48], esi
	jne	SHORT $LN6@win32munma
	cmp	DWORD PTR _minfo$[esp+60], 4096		; 00001000H
	jne	SHORT $LN6@win32munma
	cmp	DWORD PTR _minfo$[esp+56], edi
	ja	SHORT $LN6@win32munma

; 1341 :       return -1;
; 1342 :     if (VirtualFree(cptr, 0, MEM_RELEASE) == 0)

	push	32768					; 00008000H
	push	0
	push	esi
	call	ebx
	test	eax, eax
	je	SHORT $LN6@win32munma

; 1343 :       return -1;
; 1344 :     cptr += minfo.RegionSize;

	add	esi, DWORD PTR _minfo$[esp+56]

; 1345 :     size -= minfo.RegionSize;

	sub	edi, DWORD PTR _minfo$[esp+56]
	jne	SHORT $LL2@win32munma
$LN3@win32munma:
	pop	edi

; 1346 :   }
; 1347 :   return 0;
; 1348 : }

	pop	esi
	pop	ebp
	xor	eax, eax
	pop	ebx
	add	esp, 28					; 0000001cH
	ret	0
$LN6@win32munma:
	pop	edi
	pop	esi
	pop	ebp
	or	eax, -1
	pop	ebx
	add	esp, 28					; 0000001cH
	ret	0
_win32munmap ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_segment_holding PROC
; _m$ = ecx
; _addr$ = edx

; 2066 :   msegmentptr sp = &m->seg;

	lea	eax, DWORD PTR [ecx+440]
	push	esi
$LL2@segment_ho:

; 2067 :   for (;;) {
; 2068 :     if (addr >= sp->base && addr < sp->base + sp->size)

	mov	esi, DWORD PTR [eax]
	cmp	edx, esi
	jb	SHORT $LN13@segment_ho
	mov	ecx, DWORD PTR [eax+4]
	add	ecx, esi
	cmp	edx, ecx
	jb	SHORT $LN3@segment_ho
$LN13@segment_ho:

; 2069 :       return sp;
; 2070 :     if ((sp = sp->next) == 0)

	mov	eax, DWORD PTR [eax+8]
	test	eax, eax
	jne	SHORT $LL2@segment_ho
$LN3@segment_ho:
	pop	esi

; 2071 :       return 0;
; 2072 :   }
; 2073 : }

	ret	0
_segment_holding ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_has_segment_link PROC
; _m$ = ecx
; _ss$ = edx

; 2076 : static int has_segment_link(mstate m, msegmentptr ss) {

	push	esi

; 2077 :   msegmentptr sp = &m->seg;
; 2078 :   for (;;) {
; 2079 :     if ((char*)sp >= ss->base && (char*)sp < ss->base + ss->size)

	mov	esi, DWORD PTR [edx]
	lea	eax, DWORD PTR [ecx+440]
	npad	7
$LL2@has_segmen:
	cmp	eax, esi
	jb	SHORT $LN5@has_segmen
	mov	ecx, DWORD PTR [edx+4]
	add	ecx, esi
	cmp	eax, ecx
	jb	SHORT $LN10@has_segmen
$LN5@has_segmen:

; 2081 :     if ((sp = sp->next) == 0)

	mov	eax, DWORD PTR [eax+8]
	test	eax, eax
	jne	SHORT $LL2@has_segmen
	pop	esi

; 2082 :       return 0;
; 2083 :   }
; 2084 : }

	ret	0
$LN10@has_segmen:

; 2080 :       return 1;

	mov	eax, 1
	pop	esi

; 2082 :       return 0;
; 2083 :   }
; 2084 : }

	ret	0
_has_segment_link ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_system_info$1 = -36					; size = 36
_init_mparams PROC

; 2419 : static int init_mparams(void) {

	sub	esp, 36					; 00000024H

; 2420 :   if (mparams.page_size == 0) {

	cmp	DWORD PTR _mparams+4, 0
	jne	SHORT $LN4@init_mpara

; 2421 :     size_t s;
; 2422 : 
; 2423 :     mparams.mmap_threshold = DEFAULT_MMAP_THRESHOLD;
; 2424 :     mparams.trim_threshold = DEFAULT_TRIM_THRESHOLD;
; 2425 : #if MORECORE_CONTIGUOUS
; 2426 :     mparams.default_mflags = USE_LOCK_BIT|USE_MMAP_BIT;
; 2427 : #else  /* MORECORE_CONTIGUOUS */
; 2428 :     mparams.default_mflags = USE_LOCK_BIT|USE_MMAP_BIT|USE_NONCONTIGUOUS_BIT;
; 2429 : #endif /* MORECORE_CONTIGUOUS */
; 2430 : 
; 2431 : #if (FOOTERS && !INSECURE)
; 2432 :     {
; 2433 : #if USE_DEV_RANDOM
; 2434 :       int fd;
; 2435 :       unsigned char buf[sizeof(size_t)];
; 2436 :       /* Try to use /dev/urandom, else fall back on using time */
; 2437 :       if ((fd = open("/dev/urandom", O_RDONLY)) >= 0 &&
; 2438 :           read(fd, buf, sizeof(buf)) == sizeof(buf)) {
; 2439 :         s = *((size_t *) buf);
; 2440 :         close(fd);
; 2441 :       }
; 2442 :       else
; 2443 : #endif /* USE_DEV_RANDOM */
; 2444 :         s = (size_t)(time(0) ^ (size_t)0x55555555U);
; 2445 : 
; 2446 :       s |= (size_t)8U;    /* ensure nonzero */
; 2447 :       s &= ~(size_t)7U;   /* improve chances of fault for bad values */
; 2448 : 
; 2449 :     }
; 2450 : #else /* (FOOTERS && !INSECURE) */
; 2451 :     s = (size_t)0x58585858U;
; 2452 : #endif /* (FOOTERS && !INSECURE) */
; 2453 :     ACQUIRE_MAGIC_INIT_LOCK();
; 2454 :     if (mparams.magic == 0) {

	cmp	DWORD PTR _mparams, 0
	mov	DWORD PTR _mparams+12, 262144		; 00040000H
	mov	DWORD PTR _mparams+16, 2097152		; 00200000H
	mov	DWORD PTR _mparams+20, 5
	jne	SHORT $LN3@init_mpara

; 2455 :       mparams.magic = s;

	mov	DWORD PTR _mparams, 1482184792		; 58585858H

; 2456 :       /* Set up lock for main malloc area */
; 2457 :       INITIAL_LOCK(&gm->mutex);
; 2458 :       gm->mflags = mparams.default_mflags;

	mov	DWORD PTR __gm_+436, 5
$LN3@init_mpara:

; 2459 :     }
; 2460 :     RELEASE_MAGIC_INIT_LOCK();
; 2461 : 
; 2462 : #ifndef WIN32
; 2463 :     mparams.page_size = malloc_getpagesize;
; 2464 :     mparams.granularity = ((DEFAULT_GRANULARITY != 0)?
; 2465 :                            DEFAULT_GRANULARITY : mparams.page_size);
; 2466 : #else /* WIN32 */
; 2467 :     {
; 2468 :       SYSTEM_INFO system_info;
; 2469 :       GetSystemInfo(&system_info);

	lea	eax, DWORD PTR _system_info$1[esp+36]
	push	eax
	call	DWORD PTR __imp__GetSystemInfo@4

; 2470 :       mparams.page_size = system_info.dwPageSize;
; 2471 :       mparams.granularity = system_info.dwAllocationGranularity;

	mov	ecx, DWORD PTR _system_info$1[esp+64]
	mov	edx, DWORD PTR _system_info$1[esp+40]
	mov	DWORD PTR _mparams+4, edx
	mov	DWORD PTR _mparams+8, ecx

; 2472 :     }
; 2473 : #endif /* WIN32 */
; 2474 : 
; 2475 :     /* Sanity-check configuration:
; 2476 :        size_t must be unsigned and as wide as pointer type.
; 2477 :        ints must be at least 4 bytes.
; 2478 :        alignment must be at least 8.
; 2479 :        Alignment, min chunk size, and page size must all be powers of 2.
; 2480 :     */
; 2481 :     if ((sizeof(size_t) != sizeof(char*)) ||
; 2482 :         (MAX_SIZE_T < MIN_CHUNK_SIZE)  ||
; 2483 :         (sizeof(int) < 4)  ||
; 2484 :         (MALLOC_ALIGNMENT < (size_t)8U) ||
; 2485 :         ((MALLOC_ALIGNMENT    & (MALLOC_ALIGNMENT-SIZE_T_ONE))    != 0) ||
; 2486 :         ((MCHUNK_SIZE         & (MCHUNK_SIZE-SIZE_T_ONE))         != 0) ||
; 2487 :         ((mparams.granularity & (mparams.granularity-SIZE_T_ONE)) != 0) ||

	lea	eax, DWORD PTR [ecx-1]
	test	eax, ecx
	jne	SHORT $LN5@init_mpara
	lea	eax, DWORD PTR [edx-1]
	test	eax, edx
	je	SHORT $LN4@init_mpara
$LN5@init_mpara:

; 2488 :         ((mparams.page_size   & (mparams.page_size-SIZE_T_ONE))   != 0))
; 2489 :       ABORT;

	call	DWORD PTR __imp__abort
$LN4@init_mpara:

; 2490 :   }
; 2491 :   return 0;

	xor	eax, eax

; 2492 : }

	add	esp, 36					; 00000024H
	ret	0
$LN7@init_mpara:
_init_mparams ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_nfree$1$ = -16						; size = 4
_mfree$1$ = -12						; size = 4
_sum$1$ = -8						; size = 4
_s$1$ = -4						; size = 4
$T1 = 8							; size = 4
_internal_mallinfo PROC
; _m$dead$ = ecx

; 2788 : static struct mallinfo internal_mallinfo(mstate m) {

	sub	esp, 16					; 00000010H
	push	ebx

; 2789 :   struct mallinfo nm = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };

	mov	ebx, DWORD PTR $T1[esp+16]
	push	esi

; 2790 :   if (!PREACTION(m)) {
; 2791 :     check_malloc_state(m);
; 2792 :     if (is_initialized(m)) {

	mov	esi, DWORD PTR __gm_+24
	mov	DWORD PTR [ebx], 0
	mov	DWORD PTR [ebx+4], 0
	mov	DWORD PTR [ebx+8], 0
	mov	DWORD PTR [ebx+12], 0
	mov	DWORD PTR [ebx+16], 0
	mov	DWORD PTR [ebx+20], 0
	mov	DWORD PTR [ebx+24], 0
	mov	DWORD PTR [ebx+28], 0
	mov	DWORD PTR [ebx+32], 0
	mov	DWORD PTR [ebx+36], 0
	test	esi, esi
	je	$LN22@internal_m

; 2793 :       size_t nfree = SIZE_T_ONE; /* top always free */
; 2794 :       size_t mfree = m->topsize + TOP_FOOT_SIZE;

	mov	eax, DWORD PTR __gm_+12

; 2795 :       size_t sum = mfree;
; 2796 :       msegmentptr s = &m->seg;

	mov	edx, OFFSET __gm_+440
	add	eax, 40					; 00000028H
	mov	DWORD PTR _nfree$1$[esp+24], 1
	mov	DWORD PTR _mfree$1$[esp+24], eax
	mov	DWORD PTR _sum$1$[esp+24], eax
	mov	DWORD PTR _s$1$[esp+24], edx
	push	edi
	npad	2
$LL2@internal_m:

; 2797 :       while (s != 0) {
; 2798 :         mchunkptr q = align_as_chunk(s->base);

	mov	edi, DWORD PTR [edx]
	mov	eax, edi
	and	eax, 7
	je	SHORT $LN13@internal_m
$LN12@internal_m:
	neg	eax
	and	eax, 7
$LN13@internal_m:
	add	eax, edi

; 2799 :         while (segment_holds(s, q) &&
; 2800 :                q != m->top && q->head != FENCEPOST_HEAD) {

	cmp	eax, edi
	jb	SHORT $LN5@internal_m
	mov	ebx, DWORD PTR [edx+4]
	add	ebx, edi
	npad	7
$LL4@internal_m:
	cmp	eax, ebx
	jae	SHORT $LN23@internal_m
	cmp	eax, esi
	je	SHORT $LN23@internal_m
	mov	ecx, DWORD PTR [eax+4]
	cmp	ecx, 7
	je	SHORT $LN23@internal_m

; 2801 :           size_t sz = chunksize(q);

	mov	esi, ecx

; 2802 :           sum += sz;
; 2803 :           if (!cinuse(q)) {

	mov	edx, ecx

; 2804 :             mfree += sz;
; 2805 :             ++nfree;
; 2806 :           }
; 2807 :           q = next_chunk(q);

	and	ecx, -4					; fffffffcH
	and	esi, -4					; fffffffcH
	add	DWORD PTR _sum$1$[esp+28], esi
	add	eax, ecx
	mov	ecx, DWORD PTR _nfree$1$[esp+28]
	inc	ecx
	and	edx, 2
	cmovne	ecx, DWORD PTR _nfree$1$[esp+28]
	mov	DWORD PTR _nfree$1$[esp+28], ecx
	mov	ecx, DWORD PTR _mfree$1$[esp+28]
	add	ecx, esi
	mov	esi, DWORD PTR __gm_+24
	test	edx, 2
	cmovne	ecx, DWORD PTR _mfree$1$[esp+28]
	mov	DWORD PTR _mfree$1$[esp+28], ecx
	cmp	eax, edi
	jae	SHORT $LL4@internal_m
$LN23@internal_m:
	mov	edx, DWORD PTR _s$1$[esp+28]
$LN5@internal_m:

; 2808 :         }
; 2809 :         s = s->next;

	mov	edx, DWORD PTR [edx+8]
	mov	DWORD PTR _s$1$[esp+28], edx
	test	edx, edx
	jne	SHORT $LL2@internal_m

; 2810 :       }
; 2811 : 
; 2812 :       nm.arena    = sum;

	mov	ebx, DWORD PTR $T1[esp+24]

; 2813 :       nm.ordblks  = nfree;

	mov	ecx, DWORD PTR _nfree$1$[esp+28]

; 2814 :       nm.hblkhd   = m->footprint - sum;

	mov	edx, DWORD PTR __gm_+428
	mov	eax, DWORD PTR _sum$1$[esp+28]
	mov	DWORD PTR [ebx+4], ecx
	mov	ecx, edx
	sub	ecx, eax
	mov	DWORD PTR [ebx], eax

; 2815 :       nm.usmblks  = m->max_footprint;
; 2816 :       nm.uordblks = m->footprint - mfree;

	mov	eax, DWORD PTR _mfree$1$[esp+28]
	sub	edx, eax
	mov	DWORD PTR [ebx+16], ecx
	mov	ecx, DWORD PTR __gm_+432

; 2817 :       nm.fordblks = mfree;

	mov	DWORD PTR [ebx+32], eax

; 2818 :       nm.keepcost = m->topsize;

	mov	eax, DWORD PTR __gm_+12
	mov	DWORD PTR [ebx+20], ecx
	mov	DWORD PTR [ebx+28], edx
	mov	DWORD PTR [ebx+36], eax

; 2819 :     }
; 2820 : 
; 2821 :     POSTACTION(m);
; 2822 :   }
; 2823 :   return nm;

	pop	edi
$LN22@internal_m:

; 2824 : }

	pop	esi
	mov	eax, ebx
	pop	ebx
	add	esp, 16					; 00000010H
	ret	0
_internal_mallinfo ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_mmap_alloc PROC
; _m$ = ecx
; _nb$ = edx

; 3121 :   size_t mmsize = granularity_align(nb + SIX_SIZE_T_SIZES + CHUNK_ALIGN_MASK);

	mov	eax, DWORD PTR _mparams+8
	push	esi
	push	edi
	lea	edi, DWORD PTR [edx+31]
	mov	esi, ecx
	add	edi, eax
	dec	eax
	not	eax
	and	edi, eax

; 3122 :   if (mmsize > nb) {     /* Check for wrap around 0 */

	cmp	edi, edx
	jbe	SHORT $LN3@mmap_alloc

; 1327 :   void* ptr = VirtualAlloc(0, size, MEM_RESERVE|MEM_COMMIT|MEM_TOP_DOWN,

	push	4
	push	1060864					; 00103000H
	push	edi
	push	0
	call	DWORD PTR __imp__VirtualAlloc@16

; 1328 :                            PAGE_READWRITE);
; 1329 :   return (ptr != 0)? ptr: MFAIL;

	or	edx, -1
	test	eax, eax
	cmovne	edx, eax

; 3123 :     char* mm = (char*)(DIRECT_MMAP(mmsize));
; 3124 :     if (mm != CMFAIL) {

	cmp	edx, -1
	je	SHORT $LN3@mmap_alloc

; 3125 :       size_t offset = align_offset(chunk2mem(mm));

	mov	eax, edx
	and	eax, 7
	je	SHORT $LN8@mmap_alloc
$LN7@mmap_alloc:
	neg	eax
	and	eax, 7
$LN8@mmap_alloc:

; 3126 :       size_t psize = mmsize - offset - MMAP_FOOT_PAD;

	mov	ecx, edi
	sub	ecx, eax
	push	ebx

; 3127 :       mchunkptr p = (mchunkptr)(mm + offset);

	lea	ebx, DWORD PTR [eax+edx]

; 3128 :       p->prev_foot = offset | IS_MMAPPED_BIT;

	or	eax, 1
	mov	DWORD PTR [ebx], eax

; 3129 :       (p)->head = (psize|CINUSE_BIT);

	lea	eax, DWORD PTR [ecx-16]
	or	eax, 2
	mov	DWORD PTR [ebx+4], eax

; 3130 :       mark_inuse_foot(m, p, psize);
; 3131 :       chunk_plus_offset(p, psize)->head = FENCEPOST_HEAD;

	mov	DWORD PTR [ebx+ecx-12], 7

; 3132 :       chunk_plus_offset(p, psize+SIZE_T_SIZE)->head = 0;

	mov	DWORD PTR [ebx+ecx-8], 0

; 3133 : 
; 3134 :       if (mm < m->least_addr)

	cmp	edx, DWORD PTR [esi+16]
	jae	SHORT $LN4@mmap_alloc

; 3135 :         m->least_addr = mm;

	mov	DWORD PTR [esi+16], edx
$LN4@mmap_alloc:

; 3136 :       if ((m->footprint += mmsize) > m->max_footprint)

	mov	eax, DWORD PTR [esi+428]
	add	eax, edi
	mov	DWORD PTR [esi+428], eax
	cmp	eax, DWORD PTR [esi+432]
	jbe	SHORT $LN5@mmap_alloc

; 3137 :         m->max_footprint = m->footprint;

	mov	DWORD PTR [esi+432], eax
$LN5@mmap_alloc:

; 3138 :       assert(is_aligned(chunk2mem(p)));
; 3139 :       check_mmapped_chunk(m, p);
; 3140 :       return chunk2mem(p);

	lea	eax, DWORD PTR [ebx+8]
	pop	ebx
	pop	edi

; 3144 : }

	pop	esi
	ret	0
$LN3@mmap_alloc:
	pop	edi

; 3141 :     }
; 3142 :   }
; 3143 :   return 0;

	xor	eax, eax

; 3144 : }

	pop	esi
	ret	0
_mmap_alloc ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_psize$ = 8						; size = 4
_init_top PROC
; _m$ = ecx
; _p$ = edx

; 3185 :   /* Ensure alignment */
; 3186 :   size_t offset = align_offset(chunk2mem(p));

	mov	eax, edx
	push	esi
	mov	esi, ecx
	and	eax, 7
	je	SHORT $LN4@init_top
$LN3@init_top:
	neg	eax
	and	eax, 7
$LN4@init_top:

; 3187 :   p = (mchunkptr)((char*)p + offset);
; 3188 :   psize -= offset;

	mov	ecx, DWORD PTR _psize$[esp]
	add	edx, eax
	sub	ecx, eax

; 3189 : 
; 3190 :   m->top = p;

	mov	DWORD PTR [esi+24], edx

; 3191 :   m->topsize = psize;
; 3192 :   p->head = psize | PINUSE_BIT;

	mov	eax, ecx
	mov	DWORD PTR [esi+12], ecx
	or	eax, 1
	mov	DWORD PTR [edx+4], eax

; 3193 :   /* set size of fake trailing chunk holding overhead space only once */
; 3194 :   chunk_plus_offset(p, psize)->head = TOP_FOOT_SIZE;
; 3195 :   m->trim_check = mparams.trim_threshold; /* reset on each update */

	mov	eax, DWORD PTR _mparams+16
	mov	DWORD PTR [edx+ecx+4], 40		; 00000028H
	mov	DWORD PTR [esi+28], eax
	pop	esi

; 3196 : }

	ret	0
_init_top ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_init_bins PROC
; _m$ = ecx

; 3200 :   /* Establish circular links for smallbins */
; 3201 :   bindex_t i;
; 3202 :   for (i = 0; i < NSMALLBINS; ++i) {

	lea	eax, DWORD PTR [ecx+36]
	mov	edx, 32					; 00000020H
	npad	8
$LL4@init_bins:

; 3203 :     sbinptr bin = smallbin_at(m,i);
; 3204 :     bin->fd = bin->bk = bin;

	mov	DWORD PTR [eax+12], eax
	mov	DWORD PTR [eax+8], eax
	add	eax, 8
	sub	edx, 1
	jne	SHORT $LL4@init_bins

; 3205 :   }
; 3206 : }

	ret	0
_init_bins ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_p$1$ = -12						; size = 4
_XP$1$ = -8						; size = 4
_nsize$1$ = -4						; size = 4
_RP$1$ = 8						; size = 4
_oldbase$ = 8						; size = 4
_q$1$ = 12						; size = 4
_nb$ = 12						; size = 4
_prepend_alloc PROC
; _m$ = ecx
; _newbase$ = edx

; 3229 :                            size_t nb) {

	sub	esp, 12					; 0000000cH

; 3230 :   mchunkptr p = align_as_chunk(newbase);

	mov	eax, edx
	push	ebx
	push	ebp
	push	esi
	mov	esi, ecx
	push	edi
	and	eax, 7
	je	SHORT $LN68@prepend_al
$LN67@prepend_al:
	neg	eax
	and	eax, 7
$LN68@prepend_al:

; 3231 :   mchunkptr oldfirst = align_as_chunk(oldbase);

	mov	ecx, DWORD PTR _oldbase$[esp+24]
	add	edx, eax
	mov	eax, ecx
	mov	DWORD PTR _p$1$[esp+28], edx
	and	eax, 7
	je	SHORT $LN70@prepend_al
$LN69@prepend_al:
	neg	eax
	and	eax, 7
$LN70@prepend_al:
	lea	edi, DWORD PTR [eax+ecx]

; 3232 :   size_t psize = (char*)oldfirst - (char*)p;
; 3233 :   mchunkptr q = chunk_plus_offset(p, nb);

	mov	eax, DWORD PTR _nb$[esp+24]

; 3234 :   size_t qsize = psize - nb;

	mov	ecx, DWORD PTR _p$1$[esp+28]
	mov	ebp, edi
	sub	ebp, ecx
	add	edx, eax
	sub	ebp, eax
	mov	DWORD PTR _q$1$[esp+24], edx

; 3235 :   set_size_and_pinuse_of_inuse_chunk(m, p, nb);

	or	eax, 3
	mov	DWORD PTR [ecx+4], eax

; 3236 : 
; 3237 :   assert((char*)oldfirst > (char*)q);
; 3238 :   assert(pinuse(oldfirst));
; 3239 :   assert(qsize >= MIN_CHUNK_SIZE);
; 3240 : 
; 3241 :   /* consolidate remainder with first chunk of old base */
; 3242 :   if (oldfirst == m->top) {

	cmp	edi, DWORD PTR [esi+24]
	jne	SHORT $LN7@prepend_al

; 3243 :     size_t tsize = m->topsize += qsize;

	add	DWORD PTR [esi+12], ebp
	mov	eax, DWORD PTR [esi+12]
	pop	edi

; 3244 :     m->top = q;
; 3245 :     q->head = tsize | PINUSE_BIT;

	or	eax, 1
	mov	DWORD PTR [esi+24], edx

; 3267 : }

	pop	esi
	mov	DWORD PTR [edx+4], eax
	mov	eax, ecx
	pop	ebp
	add	eax, 8
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN7@prepend_al:

; 3246 :     check_top_chunk(m, q);
; 3247 :   }
; 3248 :   else if (oldfirst == m->dv) {

	cmp	edi, DWORD PTR [esi+20]
	jne	SHORT $LN9@prepend_al

; 3249 :     size_t dsize = m->dvsize += qsize;

	add	DWORD PTR [esi+8], ebp
	mov	ecx, DWORD PTR [esi+8]

; 3250 :     m->dv = q;
; 3251 :     set_size_and_pinuse_of_free_chunk(q, dsize);

	mov	eax, ecx
	pop	edi
	mov	DWORD PTR [esi+20], edx
	or	eax, 1
	mov	DWORD PTR [edx+4], eax

; 3262 :     check_free_chunk(m, q);
; 3263 :   }
; 3264 : 
; 3265 :   check_malloced_chunk(m, chunk2mem(p), nb);
; 3266 :   return chunk2mem(p);

	mov	eax, DWORD PTR _p$1$[esp+24]

; 3267 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [ecx+edx], ecx
	add	eax, 8
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN9@prepend_al:

; 3252 :   }
; 3253 :   else {
; 3254 :     if (!cinuse(oldfirst)) {

	mov	eax, DWORD PTR [edi+4]
	test	al, 2
	jne	$LN11@prepend_al

; 3255 :       size_t nsize = chunksize(oldfirst);

	and	eax, -4					; fffffffcH

; 3256 :       unlink_chunk(m, oldfirst, nsize);

	mov	ebx, eax
	mov	DWORD PTR _nsize$1$[esp+28], eax
	shr	ebx, 3
	cmp	ebx, 32					; 00000020H
	jae	SHORT $LN12@prepend_al
	mov	ecx, DWORD PTR [edi+8]
	mov	eax, DWORD PTR [edi+12]
	cmp	ecx, eax
	jne	SHORT $LN14@prepend_al
	mov	eax, DWORD PTR [esi]
	btr	eax, ebx
	mov	DWORD PTR [esi], eax
	jmp	$LN39@prepend_al
$LN14@prepend_al:
	lea	ebx, DWORD PTR [ebx*8+36]
	add	ebx, esi
	cmp	ecx, ebx
	je	SHORT $LN90@prepend_al
	cmp	ecx, DWORD PTR [esi+16]
	jb	$LN64@prepend_al
$LN90@prepend_al:
	cmp	eax, ebx
	je	SHORT $LN19@prepend_al
	cmp	eax, DWORD PTR [esi+16]
	jb	$LN64@prepend_al
$LN19@prepend_al:
	mov	DWORD PTR [ecx+12], eax
	mov	DWORD PTR [eax+8], ecx
	jmp	$LN39@prepend_al
$LN12@prepend_al:
	mov	ecx, DWORD PTR [edi+12]
	mov	ebx, DWORD PTR [edi+24]
	mov	DWORD PTR _XP$1$[esp+28], ebx
	cmp	ecx, edi
	je	SHORT $LN20@prepend_al
	mov	eax, DWORD PTR [edi+8]
	cmp	eax, DWORD PTR [esi+16]
	jb	$LN64@prepend_al
	mov	DWORD PTR [eax+12], ecx
	mov	DWORD PTR [ecx+8], eax
	jmp	SHORT $LN28@prepend_al
$LN20@prepend_al:
	mov	ecx, DWORD PTR [edi+20]
	lea	eax, DWORD PTR [edi+20]
	mov	DWORD PTR _RP$1$[esp+24], eax
	test	ecx, ecx
	jne	SHORT $LN99@prepend_al
	mov	ecx, DWORD PTR [edi+16]
	lea	eax, DWORD PTR [edi+16]
	mov	DWORD PTR _RP$1$[esp+24], eax
	test	ecx, ecx
	je	SHORT $LN28@prepend_al
$LN99@prepend_al:
	mov	edx, DWORD PTR _RP$1$[esp+24]
$LL2@prepend_al:
	mov	ebx, DWORD PTR [ecx+20]
	lea	eax, DWORD PTR [ecx+20]
	test	ebx, ebx
	jne	SHORT $LN26@prepend_al
	mov	ebx, DWORD PTR [ecx+16]
	lea	eax, DWORD PTR [ecx+16]
	test	ebx, ebx
	je	SHORT $LN3@prepend_al
$LN26@prepend_al:
	mov	edx, eax
	mov	ecx, ebx
	jmp	SHORT $LL2@prepend_al
$LN3@prepend_al:
	cmp	edx, DWORD PTR [esi+16]
	mov	DWORD PTR _RP$1$[esp+24], edx
	mov	edx, DWORD PTR _q$1$[esp+24]
	jb	$LN64@prepend_al
	mov	eax, DWORD PTR _RP$1$[esp+24]
	mov	ebx, DWORD PTR _XP$1$[esp+28]
	mov	DWORD PTR [eax], 0
$LN28@prepend_al:
	test	ebx, ebx
	je	SHORT $LN39@prepend_al
	mov	eax, DWORD PTR [edi+28]
	cmp	edi, DWORD PTR [esi+eax*4+300]
	jne	SHORT $LN30@prepend_al
	mov	DWORD PTR [esi+eax*4+300], ecx
	test	ecx, ecx
	jne	SHORT $LN85@prepend_al
	mov	ecx, DWORD PTR [esi+4]
	mov	eax, DWORD PTR [edi+28]
	btr	ecx, eax
	mov	DWORD PTR [esi+4], ecx
	jmp	SHORT $LN39@prepend_al
$LN30@prepend_al:
	cmp	ebx, DWORD PTR [esi+16]
	jb	$LN64@prepend_al
	cmp	DWORD PTR [ebx+16], edi
	jne	SHORT $LN35@prepend_al
	mov	DWORD PTR [ebx+16], ecx
	jmp	SHORT $LN36@prepend_al
$LN35@prepend_al:
	mov	DWORD PTR [ebx+20], ecx
$LN36@prepend_al:
	test	ecx, ecx
	je	SHORT $LN39@prepend_al
$LN85@prepend_al:
	cmp	ecx, DWORD PTR [esi+16]
	jb	$LN64@prepend_al
	mov	DWORD PTR [ecx+24], ebx
	mov	eax, DWORD PTR [edi+16]
	test	eax, eax
	je	SHORT $LN42@prepend_al
	cmp	eax, DWORD PTR [esi+16]
	jb	$LN64@prepend_al
	mov	DWORD PTR [ecx+16], eax
	mov	DWORD PTR [eax+24], ecx
$LN42@prepend_al:
	mov	eax, DWORD PTR [edi+20]
	test	eax, eax
	je	SHORT $LN39@prepend_al
	cmp	eax, DWORD PTR [esi+16]
	jb	$LN64@prepend_al
	mov	DWORD PTR [ecx+20], eax
	mov	DWORD PTR [eax+24], ecx
$LN39@prepend_al:

; 3257 :       oldfirst = chunk_plus_offset(oldfirst, nsize);

	add	edi, DWORD PTR _nsize$1$[esp+28]

; 3258 :       qsize += nsize;

	add	ebp, DWORD PTR _nsize$1$[esp+28]
$LN11@prepend_al:

; 3259 :     }
; 3260 :     set_free_with_pinuse(q, qsize, oldfirst);

	and	DWORD PTR [edi+4], -2			; fffffffeH
	mov	eax, ebp

; 3261 :     insert_chunk(m, q, qsize);

	mov	ecx, ebp
	or	eax, 1
	shr	ecx, 3
	mov	DWORD PTR [edx+4], eax
	mov	DWORD PTR [edx+ebp], ebp
	cmp	ecx, 32					; 00000020H
	jae	SHORT $LN46@prepend_al
	mov	ebp, DWORD PTR [esi]
	lea	ebx, DWORD PTR [esi+36]
	mov	eax, 1
	lea	ebx, DWORD PTR [ebx+ecx*8]
	shl	eax, cl
	mov	edi, ebx
	test	eax, ebp
	jne	SHORT $LN48@prepend_al

; 3262 :     check_free_chunk(m, q);
; 3263 :   }
; 3264 : 
; 3265 :   check_malloced_chunk(m, chunk2mem(p), nb);
; 3266 :   return chunk2mem(p);

	mov	eax, DWORD PTR _p$1$[esp+28]
	bts	ebp, ecx
	mov	DWORD PTR [esi], ebp
	add	eax, 8
	mov	DWORD PTR [ebx+8], edx
	mov	DWORD PTR [edi+12], edx
	mov	DWORD PTR [edx+8], edi
	pop	edi

; 3267 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [edx+12], ebx
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN48@prepend_al:

; 3261 :     insert_chunk(m, q, qsize);

	mov	edi, DWORD PTR [ebx+8]
	cmp	edi, DWORD PTR [esi+16]
	jb	$LN64@prepend_al

; 3262 :     check_free_chunk(m, q);
; 3263 :   }
; 3264 : 
; 3265 :   check_malloced_chunk(m, chunk2mem(p), nb);
; 3266 :   return chunk2mem(p);

	mov	eax, DWORD PTR _p$1$[esp+28]
	mov	DWORD PTR [ebx+8], edx
	add	eax, 8
	mov	DWORD PTR [edi+12], edx
	mov	DWORD PTR [edx+8], edi
	pop	edi

; 3267 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [edx+12], ebx
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN46@prepend_al:

; 3261 :     insert_chunk(m, q, qsize);

	mov	edi, ebp
	shr	edi, 8
	test	edi, edi
	jne	SHORT $LN52@prepend_al
	xor	ecx, ecx
	jmp	SHORT $LN55@prepend_al
$LN52@prepend_al:
	cmp	edi, 65535				; 0000ffffH
	jbe	SHORT $LN54@prepend_al
	mov	ecx, 31					; 0000001fH
	jmp	SHORT $LN55@prepend_al
$LN54@prepend_al:
	lea	eax, DWORD PTR [edi-256]
	shr	eax, 16					; 00000010H
	and	eax, 8
	mov	ecx, eax
	shl	edi, cl
	lea	ecx, DWORD PTR [edi-4096]
	shr	ecx, 16					; 00000010H
	and	ecx, 4
	shl	edi, cl
	add	eax, ecx
	lea	ecx, DWORD PTR [edi-16384]
	shr	ecx, 16					; 00000010H
	and	ecx, 2
	shl	edi, cl
	shr	edi, 15					; 0000000fH
	sub	edi, ecx
	sub	edi, eax
	mov	eax, ebp
	lea	ecx, DWORD PTR [edi+21]
	shr	eax, cl
	lea	ecx, DWORD PTR [edi+14]
	and	eax, 1
	lea	ecx, DWORD PTR [eax+ecx*2]
$LN55@prepend_al:
	mov	eax, 1
	mov	DWORD PTR [edx+28], ecx
	mov	DWORD PTR [edx+20], 0
	lea	ebx, DWORD PTR [esi+300]
	mov	DWORD PTR [edx+16], 0
	lea	ebx, DWORD PTR [ebx+ecx*4]
	mov	edi, DWORD PTR [esi+4]
	shl	eax, cl
	test	eax, edi
	jne	SHORT $LN56@prepend_al

; 3262 :     check_free_chunk(m, q);
; 3263 :   }
; 3264 : 
; 3265 :   check_malloced_chunk(m, chunk2mem(p), nb);
; 3266 :   return chunk2mem(p);

	mov	eax, DWORD PTR _p$1$[esp+28]
	bts	edi, ecx
	mov	DWORD PTR [esi+4], edi
	add	eax, 8
	pop	edi
	mov	DWORD PTR [ebx], edx

; 3267 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [edx+24], ebx
	mov	DWORD PTR [edx+12], edx
	mov	DWORD PTR [edx+8], edx
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN56@prepend_al:

; 3261 :     insert_chunk(m, q, qsize);

	mov	edi, DWORD PTR [ebx]
	cmp	ecx, 31					; 0000001fH
	jne	SHORT $LN71@prepend_al
	xor	eax, eax
	jmp	SHORT $LN72@prepend_al
$LN71@prepend_al:
	shr	ecx, 1
	mov	eax, 25					; 00000019H
	sub	eax, ecx
$LN72@prepend_al:
	mov	ecx, eax
	mov	ebx, ebp
	mov	eax, DWORD PTR [edi+4]
	and	eax, -4					; fffffffcH
	shl	ebx, cl
	cmp	eax, ebp
	je	SHORT $LN58@prepend_al
$LL4@prepend_al:
	mov	eax, ebx
	add	ebx, ebx
	shr	eax, 31					; 0000001fH
	add	eax, 4
	lea	ecx, DWORD PTR [edi+eax*4]
	mov	eax, DWORD PTR [ecx]
	test	eax, eax
	je	SHORT $LN60@prepend_al
	mov	edi, eax
	mov	eax, DWORD PTR [edi+4]
	and	eax, -4					; fffffffcH
	cmp	eax, ebp
	jne	SHORT $LL4@prepend_al
$LN58@prepend_al:
	mov	ecx, DWORD PTR [esi+16]
	cmp	edi, ecx
	jb	SHORT $LN64@prepend_al
	mov	eax, DWORD PTR [edi+8]
	cmp	eax, ecx
	jb	SHORT $LN64@prepend_al
	mov	DWORD PTR [eax+12], edx
	mov	DWORD PTR [edi+8], edx
	mov	DWORD PTR [edx+12], edi
	pop	edi

; 3267 : }

	pop	esi
	mov	DWORD PTR [edx+8], eax
	mov	eax, DWORD PTR _p$1$[esp+20]
	pop	ebp
	mov	DWORD PTR [edx+24], 0
	add	eax, 8
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN60@prepend_al:

; 3261 :     insert_chunk(m, q, qsize);

	cmp	ecx, DWORD PTR [esi+16]
	jb	SHORT $LN64@prepend_al

; 3262 :     check_free_chunk(m, q);
; 3263 :   }
; 3264 : 
; 3265 :   check_malloced_chunk(m, chunk2mem(p), nb);
; 3266 :   return chunk2mem(p);

	mov	eax, DWORD PTR _p$1$[esp+28]
	mov	DWORD PTR [ecx], edx
	add	eax, 8
	mov	DWORD PTR [edx+24], edi
	pop	edi

; 3267 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [edx+12], edx
	mov	DWORD PTR [edx+8], edx
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN64@prepend_al:

; 3261 :     insert_chunk(m, q, qsize);

	call	DWORD PTR __imp__abort
$LN101@prepend_al:
	int	3
_prepend_alloc ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_psize$1$ = -8						; size = 4
_tbase$1$ = -4						; size = 4
_tsize$ = 8						; size = 4
_mmapped$ = 12						; size = 4
_add_segment PROC
; _m$ = ecx
; _tbase$ = edx

; 3271 : static void add_segment(mstate m, char* tbase, size_t tsize, flag_t mmapped) {

	sub	esp, 8
	push	ebx
	mov	ebx, ecx
	mov	DWORD PTR _tbase$1$[esp+12], edx
	push	ebp
	push	esi
	push	edi

; 3272 :   /* Determine locations and sizes of segment, fenceposts, old top */
; 3273 :   char* old_top = (char*)m->top;

	mov	eax, DWORD PTR [ebx+24]

; 2066 :   msegmentptr sp = &m->seg;

	lea	ebp, DWORD PTR [ebx+440]
	mov	esi, ebp
$LL39@add_segmen:

; 2067 :   for (;;) {
; 2068 :     if (addr >= sp->base && addr < sp->base + sp->size)

	mov	edx, DWORD PTR [esi]
	cmp	eax, edx
	jb	SHORT $LN60@add_segmen
	mov	ecx, DWORD PTR [esi+4]
	add	ecx, edx
	cmp	eax, ecx
	jb	SHORT $LN40@add_segmen
$LN60@add_segmen:

; 2069 :       return sp;
; 2070 :     if ((sp = sp->next) == 0)

	mov	esi, DWORD PTR [esi+8]
	test	esi, esi
	jne	SHORT $LL39@add_segmen
$LN40@add_segmen:

; 3274 :   msegmentptr oldsp = segment_holding(m, old_top);
; 3275 :   char* old_end = oldsp->base + oldsp->size;

	mov	edi, DWORD PTR [esi+4]
	add	edi, DWORD PTR [esi]

; 3276 :   size_t ssize = pad_request(sizeof(struct malloc_segment));
; 3277 :   char* rawsp = old_end - (ssize + FOUR_SIZE_T_SIZES + CHUNK_ALIGN_MASK);

	lea	edx, DWORD PTR [edi-47]

; 3278 :   size_t offset = align_offset(chunk2mem(rawsp));

	mov	ecx, edx
	and	ecx, 7
	je	SHORT $LN33@add_segmen
$LN32@add_segmen:
	neg	ecx
	and	ecx, 7
$LN33@add_segmen:

; 3279 :   char* asp = rawsp + offset;

	lea	esi, DWORD PTR [ecx+edx]

; 3186 :   size_t offset = align_offset(chunk2mem(p));

	mov	edx, DWORD PTR _tbase$1$[esp+24]

; 3280 :   char* csp = (asp < (old_top + MIN_CHUNK_SIZE))? old_top : asp;

	lea	ecx, DWORD PTR [eax+16]
	cmp	esi, ecx

; 3281 :   mchunkptr sp = (mchunkptr)csp;
; 3282 :   msegmentptr ss = (msegmentptr)(chunk2mem(sp));
; 3283 :   mchunkptr tnext = chunk_plus_offset(sp, ssize);
; 3284 :   mchunkptr p = tnext;
; 3285 :   int nfences = 0;
; 3286 : 
; 3287 :   /* reset top to new space */
; 3288 :   init_top(m, (mchunkptr)tbase, tsize - TOP_FOOT_SIZE);

	mov	ecx, DWORD PTR _tsize$[esp+20]
	cmovb	esi, eax
	add	ecx, -40				; ffffffd8H
	mov	DWORD PTR _psize$1$[esp+24], ecx

; 3186 :   size_t offset = align_offset(chunk2mem(p));

	mov	ecx, edx
	and	ecx, 7
	je	SHORT $LN48@add_segmen
$LN47@add_segmen:
	neg	ecx
	and	ecx, 7
$LN48@add_segmen:

; 3187 :   p = (mchunkptr)((char*)p + offset);
; 3188 :   psize -= offset;

	sub	DWORD PTR _psize$1$[esp+24], ecx
	add	edx, ecx

; 3189 : 
; 3190 :   m->top = p;
; 3191 :   m->topsize = psize;

	mov	ecx, DWORD PTR _psize$1$[esp+24]
	mov	DWORD PTR [ebx+12], ecx

; 3192 :   p->head = psize | PINUSE_BIT;

	or	ecx, 1
	mov	DWORD PTR [ebx+24], edx
	mov	DWORD PTR [edx+4], ecx

; 3193 :   /* set size of fake trailing chunk holding overhead space only once */
; 3194 :   chunk_plus_offset(p, psize)->head = TOP_FOOT_SIZE;

	mov	ecx, DWORD PTR _psize$1$[esp+24]
	mov	DWORD PTR [edx+ecx+4], 40		; 00000028H

; 3293 :   *ss = m->seg; /* Push current record */

	lea	edx, DWORD PTR [esi+8]

; 3195 :   m->trim_check = mparams.trim_threshold; /* reset on each update */

	mov	ecx, DWORD PTR _mparams+16
	mov	DWORD PTR [ebx+28], ecx

; 3289 : 
; 3290 :   /* Set up segment record */
; 3291 :   assert(is_aligned(ss));
; 3292 :   set_size_and_pinuse_of_inuse_chunk(m, sp, ssize);

	mov	DWORD PTR [esi+4], 27			; 0000001bH

; 3293 :   *ss = m->seg; /* Push current record */

	mov	ecx, DWORD PTR [ebp]
	mov	DWORD PTR [edx], ecx
	mov	ecx, DWORD PTR [ebp+4]
	mov	DWORD PTR [edx+4], ecx
	mov	ecx, DWORD PTR [ebp+8]
	mov	DWORD PTR [edx+8], ecx
	mov	ecx, DWORD PTR [ebp+12]
	mov	DWORD PTR [edx+12], ecx

; 3294 :   m->seg.base = tbase;

	mov	ecx, DWORD PTR _tbase$1$[esp+24]
	mov	DWORD PTR [ebp], ecx

; 3295 :   m->seg.size = tsize;

	mov	ecx, DWORD PTR _tsize$[esp+20]
	mov	DWORD PTR [ebx+444], ecx

; 3296 :   m->seg.sflags = mmapped;

	mov	ecx, DWORD PTR _mmapped$[esp+20]
	mov	DWORD PTR [ebx+452], ecx

; 3297 :   m->seg.next = ss;
; 3298 : 
; 3299 :   /* Insert trailing fenceposts */
; 3300 :   for (;;) {
; 3301 :     mchunkptr nextp = chunk_plus_offset(p, SIZE_T_SIZE);

	lea	ecx, DWORD PTR [esi+28]
	mov	DWORD PTR [ebx+448], edx

; 3303 :     ++nfences;
; 3304 :     if ((char*)(&(nextp->head)) < old_end)

	lea	edx, DWORD PTR [ecx+4]
	mov	DWORD PTR [ecx], 7
	cmp	edx, edi
	jae	SHORT $LN8@add_segmen
	npad	11
$LL2@add_segmen:

; 3297 :   m->seg.next = ss;
; 3298 : 
; 3299 :   /* Insert trailing fenceposts */
; 3300 :   for (;;) {
; 3301 :     mchunkptr nextp = chunk_plus_offset(p, SIZE_T_SIZE);

	add	edx, 4

; 3302 :     p->head = FENCEPOST_HEAD;

	mov	DWORD PTR [ecx+4], 7
	lea	ecx, DWORD PTR [ecx+4]

; 3303 :     ++nfences;
; 3304 :     if ((char*)(&(nextp->head)) < old_end)

	cmp	edx, edi
	jb	SHORT $LL2@add_segmen
$LN8@add_segmen:

; 3305 :       p = nextp;
; 3306 :     else
; 3307 :       break;
; 3308 :   }
; 3309 :   assert(nfences >= 2);
; 3310 : 
; 3311 :   /* Insert the rest of old top into a bin as an ordinary free chunk */
; 3312 :   if (csp != old_top) {

	cmp	esi, eax
	je	$LN6@add_segmen

; 3313 :     mchunkptr q = (mchunkptr)old_top;
; 3314 :     size_t psize = csp - old_top;
; 3315 :     mchunkptr tn = chunk_plus_offset(q, psize);
; 3316 :     set_free_with_pinuse(q, psize, tn);

	and	DWORD PTR [esi+4], -2			; fffffffeH
	mov	edi, esi
	sub	edi, eax
	mov	ecx, edi
	or	ecx, 1
	mov	DWORD PTR [eax+4], ecx

; 3317 :     insert_chunk(m, q, psize);

	mov	ecx, edi
	shr	ecx, 3
	mov	DWORD PTR [esi], edi
	cmp	ecx, 32					; 00000020H
	jae	SHORT $LN11@add_segmen
	mov	ebp, DWORD PTR [ebx]
	lea	edi, DWORD PTR [ebx+36]
	mov	edx, 1
	lea	edi, DWORD PTR [edi+ecx*8]
	shl	edx, cl
	mov	esi, edi
	test	edx, ebp
	jne	SHORT $LN13@add_segmen
	bts	ebp, ecx
	mov	DWORD PTR [ebx], ebp
	mov	DWORD PTR [edi+8], eax
	mov	DWORD PTR [esi+12], eax
	mov	DWORD PTR [eax+12], edi
	pop	edi
	mov	DWORD PTR [eax+8], esi

; 3318 :   }
; 3319 : 
; 3320 :   check_top_chunk(m, m->top);
; 3321 : }

	pop	esi
	pop	ebp
	pop	ebx
	add	esp, 8
	ret	0
$LN13@add_segmen:

; 3317 :     insert_chunk(m, q, psize);

	mov	esi, DWORD PTR [edi+8]
	cmp	esi, DWORD PTR [ebx+16]
	jb	$LN29@add_segmen
	mov	DWORD PTR [edi+8], eax
	mov	DWORD PTR [esi+12], eax
	mov	DWORD PTR [eax+12], edi
	pop	edi
	mov	DWORD PTR [eax+8], esi

; 3318 :   }
; 3319 : 
; 3320 :   check_top_chunk(m, m->top);
; 3321 : }

	pop	esi
	pop	ebp
	pop	ebx
	add	esp, 8
	ret	0
$LN11@add_segmen:

; 3317 :     insert_chunk(m, q, psize);

	mov	esi, edi
	shr	esi, 8
	test	esi, esi
	jne	SHORT $LN17@add_segmen
	xor	ecx, ecx
	jmp	SHORT $LN20@add_segmen
$LN17@add_segmen:
	cmp	esi, 65535				; 0000ffffH
	jbe	SHORT $LN19@add_segmen
	mov	ecx, 31					; 0000001fH
	jmp	SHORT $LN20@add_segmen
$LN19@add_segmen:
	lea	edx, DWORD PTR [esi-256]
	shr	edx, 16					; 00000010H
	and	edx, 8
	mov	ecx, edx
	shl	esi, cl
	lea	ecx, DWORD PTR [esi-4096]
	shr	ecx, 16					; 00000010H
	and	ecx, 4
	shl	esi, cl
	add	edx, ecx
	lea	ecx, DWORD PTR [esi-16384]
	shr	ecx, 16					; 00000010H
	and	ecx, 2
	shl	esi, cl
	shr	esi, 15					; 0000000fH
	sub	esi, ecx
	sub	esi, edx
	mov	edx, edi
	lea	ecx, DWORD PTR [esi+21]
	shr	edx, cl
	lea	ecx, DWORD PTR [esi+14]
	and	edx, 1
	lea	ecx, DWORD PTR [edx+ecx*2]
$LN20@add_segmen:
	mov	edx, 1
	mov	DWORD PTR [eax+28], ecx
	mov	DWORD PTR [eax+20], 0
	lea	ebp, DWORD PTR [ebx+300]
	mov	DWORD PTR [eax+16], 0
	lea	ebp, DWORD PTR [ebp+ecx*4]
	mov	esi, DWORD PTR [ebx+4]
	shl	edx, cl
	test	edx, esi
	jne	SHORT $LN21@add_segmen
	bts	esi, ecx
	mov	DWORD PTR [ebx+4], esi
	mov	DWORD PTR [ebp], eax
	mov	DWORD PTR [eax+24], ebp

; 3318 :   }
; 3319 : 
; 3320 :   check_top_chunk(m, m->top);
; 3321 : }

	mov	DWORD PTR [eax+12], eax
	mov	DWORD PTR [eax+8], eax
$LN6@add_segmen:
	pop	edi
	pop	esi
	pop	ebp
	pop	ebx
	add	esp, 8
	ret	0
$LN21@add_segmen:

; 3317 :     insert_chunk(m, q, psize);

	mov	edx, DWORD PTR [ebp]
	cmp	ecx, 31					; 0000001fH
	jne	SHORT $LN36@add_segmen
	xor	ebp, ebp
	jmp	SHORT $LN37@add_segmen
$LN36@add_segmen:
	shr	ecx, 1
	mov	ebp, 25					; 00000019H
	sub	ebp, ecx
$LN37@add_segmen:
	mov	ecx, ebp
	mov	esi, edi
	shl	esi, cl
	mov	ecx, DWORD PTR [edx+4]
	and	ecx, -4					; fffffffcH
	cmp	ecx, edi
	je	SHORT $LN23@add_segmen
	npad	4
$LL5@add_segmen:
	mov	ecx, esi
	add	esi, esi
	shr	ecx, 31					; 0000001fH
	add	ecx, 4
	lea	ebp, DWORD PTR [edx+ecx*4]
	mov	ecx, DWORD PTR [ebp]
	test	ecx, ecx
	je	SHORT $LN25@add_segmen
	mov	edx, ecx
	mov	ecx, DWORD PTR [edx+4]
	and	ecx, -4					; fffffffcH
	cmp	ecx, edi
	jne	SHORT $LL5@add_segmen
$LN23@add_segmen:
	mov	esi, DWORD PTR [ebx+16]
	cmp	edx, esi
	jb	SHORT $LN29@add_segmen
	mov	ecx, DWORD PTR [edx+8]
	cmp	ecx, esi
	jb	SHORT $LN29@add_segmen
	pop	edi
	mov	DWORD PTR [ecx+12], eax

; 3318 :   }
; 3319 : 
; 3320 :   check_top_chunk(m, m->top);
; 3321 : }

	pop	esi
	mov	DWORD PTR [edx+8], eax
	pop	ebp
	mov	DWORD PTR [eax+8], ecx
	mov	DWORD PTR [eax+12], edx
	mov	DWORD PTR [eax+24], 0
	pop	ebx
	add	esp, 8
	ret	0
$LN25@add_segmen:

; 3317 :     insert_chunk(m, q, psize);

	cmp	ebp, DWORD PTR [ebx+16]
	jb	SHORT $LN29@add_segmen
	pop	edi
	mov	DWORD PTR [ebp], eax

; 3318 :   }
; 3319 : 
; 3320 :   check_top_chunk(m, m->top);
; 3321 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [eax+24], edx
	mov	DWORD PTR [eax+12], eax
	mov	DWORD PTR [eax+8], eax
	pop	ebx
	add	esp, 8
	ret	0
$LN29@add_segmen:

; 3317 :     insert_chunk(m, q, psize);

	call	DWORD PTR __imp__abort
$LN64@add_segmen:
	int	3
_add_segment ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
tv1094 = -8						; size = 4
_p$1$ = -8						; size = 4
_nb$1$ = -4						; size = 4
_sys_alloc PROC
; _m$ = ecx
; _nb$ = edx

; 3326 : static void* sys_alloc(mstate m, size_t nb) {

	sub	esp, 8
	push	ebx
	push	ebp
	push	esi
	mov	ebp, edx
	mov	esi, ecx
	push	edi
	mov	DWORD PTR _nb$1$[esp+24], ebp

; 3327 :   char* tbase = CMFAIL;
; 3328 :   size_t tsize = 0;
; 3329 :   flag_t mmap_flag = 0;
; 3330 : 
; 3331 :   init_mparams();

	call	_init_mparams

; 3332 : 
; 3333 :   /* Directly map large chunks */
; 3334 :   if (use_mmap(m) && nb >= mparams.mmap_threshold) {

	mov	edx, DWORD PTR __imp__VirtualAlloc@16
	or	edi, -1
	test	BYTE PTR [esi+436], 1
	je	$LN118@sys_alloc
	cmp	ebp, DWORD PTR _mparams+12
	jb	$LN118@sys_alloc

; 3121 :   size_t mmsize = granularity_align(nb + SIX_SIZE_T_SIZES + CHUNK_ALIGN_MASK);

	mov	ecx, DWORD PTR _mparams+8
	lea	ebx, DWORD PTR [ecx+31]
	lea	eax, DWORD PTR [ecx-1]
	add	ebx, ebp
	not	eax
	and	ebx, eax

; 3122 :   if (mmsize > nb) {     /* Check for wrap around 0 */

	cmp	ebx, ebp
	jbe	$LN117@sys_alloc

; 1327 :   void* ptr = VirtualAlloc(0, size, MEM_RESERVE|MEM_COMMIT|MEM_TOP_DOWN,

	push	4
	push	1060864					; 00103000H
	push	ebx
	push	0
	call	edx

; 1328 :                            PAGE_READWRITE);
; 1329 :   return (ptr != 0)? ptr: MFAIL;

	test	eax, eax
	mov	edx, edi
	cmovne	edx, eax

; 3124 :     if (mm != CMFAIL) {

	cmp	edx, edi
	je	SHORT $LN120@sys_alloc

; 3125 :       size_t offset = align_offset(chunk2mem(mm));

	mov	eax, edx
	and	eax, 7
	je	SHORT $LN70@sys_alloc
$LN69@sys_alloc:
	neg	eax
	and	eax, 7
$LN70@sys_alloc:

; 3126 :       size_t psize = mmsize - offset - MMAP_FOOT_PAD;
; 3127 :       mchunkptr p = (mchunkptr)(mm + offset);

	lea	ebp, DWORD PTR [eax+edx]
	mov	ecx, ebx
	sub	ecx, eax
	mov	DWORD PTR _p$1$[esp+24], ebp

; 3128 :       p->prev_foot = offset | IS_MMAPPED_BIT;

	or	eax, 1
	mov	DWORD PTR [ebp], eax

; 3129 :       (p)->head = (psize|CINUSE_BIT);

	lea	eax, DWORD PTR [ecx-16]
	or	eax, 2
	mov	DWORD PTR [ebp+4], eax

; 3130 :       mark_inuse_foot(m, p, psize);
; 3131 :       chunk_plus_offset(p, psize)->head = FENCEPOST_HEAD;

	mov	eax, ebp

; 3132 :       chunk_plus_offset(p, psize+SIZE_T_SIZE)->head = 0;
; 3133 : 
; 3134 :       if (mm < m->least_addr)

	mov	ebp, DWORD PTR _nb$1$[esp+24]
	mov	DWORD PTR [eax+ecx-12], 7
	mov	DWORD PTR [eax+ecx-8], 0
	cmp	edx, DWORD PTR [esi+16]
	jae	SHORT $LN66@sys_alloc

; 3135 :         m->least_addr = mm;

	mov	DWORD PTR [esi+16], edx
$LN66@sys_alloc:

; 3136 :       if ((m->footprint += mmsize) > m->max_footprint)

	mov	eax, DWORD PTR [esi+428]
	add	eax, ebx
	mov	DWORD PTR [esi+428], eax
	cmp	eax, DWORD PTR [esi+432]
	jbe	SHORT $LN67@sys_alloc

; 3137 :         m->max_footprint = m->footprint;

	mov	DWORD PTR [esi+432], eax
$LN67@sys_alloc:

; 3138 :       assert(is_aligned(chunk2mem(p)));
; 3139 :       check_mmapped_chunk(m, p);
; 3140 :       return chunk2mem(p);

	mov	eax, DWORD PTR _p$1$[esp+24]
	add	eax, 8

; 3335 :     void* mem = mmap_alloc(m, nb);
; 3336 :     if (mem != 0)

	jne	$LN1@sys_alloc
$LN120@sys_alloc:

; 3332 : 
; 3333 :   /* Directly map large chunks */
; 3334 :   if (use_mmap(m) && nb >= mparams.mmap_threshold) {

	mov	edx, DWORD PTR __imp__VirtualAlloc@16
$LN118@sys_alloc:
	mov	ecx, DWORD PTR _mparams+8
$LN117@sys_alloc:

; 3337 :       return mem;
; 3338 :   }
; 3339 : 
; 3340 :   /*
; 3341 :     Try getting memory in any of three ways (in most-preferred to
; 3342 :     least-preferred order):
; 3343 :     1. A call to MORECORE that can normally contiguously extend memory.
; 3344 :        (disabled if not MORECORE_CONTIGUOUS or not HAVE_MORECORE or
; 3345 :        or main space is mmapped or a previous contiguous call failed)
; 3346 :     2. A call to MMAP new space (disabled if not HAVE_MMAP).
; 3347 :        Note that under the default settings, if MORECORE is unable to
; 3348 :        fulfill a request, and HAVE_MMAP is true, then mmap is
; 3349 :        used as a noncontiguous system allocator. This is a useful backup
; 3350 :        strategy for systems with holes in address spaces -- in this case
; 3351 :        sbrk cannot contiguously expand the heap, but mmap may be able to
; 3352 :        find space.
; 3353 :     3. A call to MORECORE that cannot usually contiguously extend memory.
; 3354 :        (disabled if not HAVE_MORECORE)
; 3355 :   */
; 3356 : 
; 3357 :   if (MORECORE_CONTIGUOUS && !use_noncontiguous(m)) {
; 3358 :     char* br = CMFAIL;
; 3359 :     msegmentptr ss = (m->top == 0)? 0 : segment_holding(m, (char*)m->top);
; 3360 :     size_t asize = 0;
; 3361 :     ACQUIRE_MORECORE_LOCK();
; 3362 : 
; 3363 :     if (ss == 0) {  /* First time through or recovery */
; 3364 :       char* base = (char*)CALL_MORECORE(0);
; 3365 :       if (base != CMFAIL) {
; 3366 :         asize = granularity_align(nb + TOP_FOOT_SIZE + SIZE_T_ONE);
; 3367 :         /* Adjust to end on a page boundary */
; 3368 :         if (!is_page_aligned(base))
; 3369 :           asize += (page_align((size_t)base) - (size_t)base);
; 3370 :         /* Can't call MORECORE if size is negative when treated as signed */
; 3371 :         if (asize < HALF_MAX_SIZE_T &&
; 3372 :             (br = (char*)(CALL_MORECORE(asize))) == base) {
; 3373 :           tbase = base;
; 3374 :           tsize = asize;
; 3375 :         }
; 3376 :       }
; 3377 :     }
; 3378 :     else {
; 3379 :       /* Subtract out existing available top space from MORECORE request. */
; 3380 :       asize = granularity_align(nb - m->topsize + TOP_FOOT_SIZE + SIZE_T_ONE);
; 3381 :       /* Use mem here only if it did continuously extend old space */
; 3382 :       if (asize < HALF_MAX_SIZE_T &&
; 3383 :           (br = (char*)(CALL_MORECORE(asize))) == ss->base+ss->size) {
; 3384 :         tbase = br;
; 3385 :         tsize = asize;
; 3386 :       }
; 3387 :     }
; 3388 : 
; 3389 :     if (tbase == CMFAIL) {    /* Cope with partial failure */
; 3390 :       if (br != CMFAIL) {    /* Try to use/extend the space we did get */
; 3391 :         if (asize < HALF_MAX_SIZE_T &&
; 3392 :             asize < nb + TOP_FOOT_SIZE + SIZE_T_ONE) {
; 3393 :           size_t esize = granularity_align(nb + TOP_FOOT_SIZE + SIZE_T_ONE - asize);
; 3394 :           if (esize < HALF_MAX_SIZE_T) {
; 3395 :             char* end = (char*)CALL_MORECORE(esize);
; 3396 :             if (end != CMFAIL)
; 3397 :               asize += esize;
; 3398 :             else {            /* Can't use; try to release */
; 3399 :               CALL_MORECORE(-asize);
; 3400 :               br = CMFAIL;
; 3401 :             }
; 3402 :           }
; 3403 :         }
; 3404 :       }
; 3405 :       if (br != CMFAIL) {    /* Use the space we did get */
; 3406 :         tbase = br;
; 3407 :         tsize = asize;
; 3408 :       }
; 3409 :       else
; 3410 :         disable_contiguous(m); /* Don't try contiguous path in the future */
; 3411 :     }
; 3412 : 
; 3413 :     RELEASE_MORECORE_LOCK();
; 3414 :   }
; 3415 : 
; 3416 :   if (HAVE_MMAP && tbase == CMFAIL) {  /* Try MMAP */
; 3417 :     size_t req = nb + TOP_FOOT_SIZE + SIZE_T_ONE;
; 3418 :     size_t rsize = granularity_align(req);

	lea	ebx, DWORD PTR [ebp+41]
	lea	eax, DWORD PTR [ecx-1]
	add	ebx, ecx
	not	eax
	and	ebx, eax

; 3419 :     if (rsize > nb) { /* Fail if wraps around zero */

	cmp	ebx, ebp
	jbe	$LN41@sys_alloc

; 1321 :   void* ptr = VirtualAlloc(0, size, MEM_RESERVE|MEM_COMMIT, PAGE_READWRITE);

	push	4
	push	12288					; 00003000H
	push	ebx
	push	0
	call	edx

; 1322 :   return (ptr != 0)? ptr: MFAIL;

	test	eax, eax
	cmovne	edi, eax

; 3420 :       char* mp = (char*)(CALL_MMAP(rsize));
; 3421 :       if (mp != CMFAIL) {

	cmp	edi, -1
	je	$LN41@sys_alloc

; 3422 :         tbase = mp;
; 3423 :         tsize = rsize;
; 3424 :         mmap_flag = IS_MMAPPED_BIT;
; 3425 :       }
; 3426 :     }
; 3427 :   }
; 3428 : 
; 3429 :   if (HAVE_MORECORE && tbase == CMFAIL) { /* Try noncontiguous MORECORE */
; 3430 :     size_t asize = granularity_align(nb + TOP_FOOT_SIZE + SIZE_T_ONE);
; 3431 :     if (asize < HALF_MAX_SIZE_T) {
; 3432 :       char* br = CMFAIL;
; 3433 :       char* end = CMFAIL;
; 3434 :       ACQUIRE_MORECORE_LOCK();
; 3435 :       br = (char*)(CALL_MORECORE(asize));
; 3436 :       end = (char*)(CALL_MORECORE(0));
; 3437 :       RELEASE_MORECORE_LOCK();
; 3438 :       if (br != CMFAIL && end != CMFAIL && br < end) {
; 3439 :         size_t ssize = end - br;
; 3440 :         if (ssize > nb + TOP_FOOT_SIZE) {
; 3441 :           tbase = br;
; 3442 :           tsize = ssize;
; 3443 :         }
; 3444 :       }
; 3445 :     }
; 3446 :   }
; 3447 : 
; 3448 :   if (tbase != CMFAIL) {
; 3449 : 
; 3450 :     if ((m->footprint += tsize) > m->max_footprint)

	mov	eax, DWORD PTR [esi+428]
	add	eax, ebx
	mov	DWORD PTR [esi+428], eax
	cmp	eax, DWORD PTR [esi+432]
	jbe	SHORT $LN31@sys_alloc

; 3451 :       m->max_footprint = m->footprint;

	mov	DWORD PTR [esi+432], eax
$LN31@sys_alloc:

; 3452 : 
; 3453 :     if (!is_initialized(m)) { /* first-time initialization */

	cmp	DWORD PTR [esi+24], 0
	lea	eax, DWORD PTR [esi+440]
	jne	$LN32@sys_alloc

; 3454 :       m->seg.base = m->least_addr = tbase;

	mov	DWORD PTR [eax], edi
	lea	ecx, DWORD PTR [esi+36]

; 3455 :       m->seg.size = tsize;
; 3456 :       m->seg.sflags = mmap_flag;
; 3457 :       m->magic = mparams.magic;

	mov	eax, DWORD PTR _mparams
	mov	edx, 32					; 00000020H
	mov	DWORD PTR [esi+16], edi
	mov	DWORD PTR [esi+444], ebx
	mov	DWORD PTR [esi+452], 1
	mov	DWORD PTR [esi+32], eax
	npad	1
$LL85@sys_alloc:

; 3204 :     bin->fd = bin->bk = bin;

	mov	DWORD PTR [ecx+12], ecx
	mov	DWORD PTR [ecx+8], ecx
	add	ecx, 8
	sub	edx, 1
	jne	SHORT $LL85@sys_alloc

; 3458 :       init_bins(m);
; 3459 :       if (is_global(m)) 

	cmp	esi, OFFSET __gm_
	jne	SHORT $LN34@sys_alloc

; 3186 :   size_t offset = align_offset(chunk2mem(p));

	mov	eax, edi

; 3460 :         init_top(m, (mchunkptr)tbase, tsize - TOP_FOOT_SIZE);

	add	ebx, -40				; ffffffd8H

; 3186 :   size_t offset = align_offset(chunk2mem(p));

	and	eax, 7
	je	SHORT $LN90@sys_alloc
$LN89@sys_alloc:
	neg	eax
	and	eax, 7
$LN90@sys_alloc:

; 3187 :   p = (mchunkptr)((char*)p + offset);

	lea	ecx, DWORD PTR [eax+edi]

; 3188 :   psize -= offset;

	sub	ebx, eax

; 3189 : 
; 3190 :   m->top = p;
; 3191 :   m->topsize = psize;
; 3192 :   p->head = psize | PINUSE_BIT;

	mov	eax, ebx
	mov	DWORD PTR [esi+24], ecx
	or	eax, 1
	mov	DWORD PTR [esi+12], ebx
	mov	DWORD PTR [ecx+4], eax

; 3193 :   /* set size of fake trailing chunk holding overhead space only once */
; 3194 :   chunk_plus_offset(p, psize)->head = TOP_FOOT_SIZE;
; 3195 :   m->trim_check = mparams.trim_threshold; /* reset on each update */

	mov	eax, DWORD PTR _mparams+16
	mov	DWORD PTR [ecx+ebx+4], 40		; 00000028H
	mov	DWORD PTR [esi+28], eax

; 3460 :         init_top(m, (mchunkptr)tbase, tsize - TOP_FOOT_SIZE);

	jmp	$LN40@sys_alloc
$LN34@sys_alloc:

; 3461 :       else {
; 3462 :         /* Offset top by embedded malloc_state */
; 3463 :         mchunkptr mn = next_chunk(mem2chunk(m));

	mov	eax, DWORD PTR [esi-4]
	lea	ecx, DWORD PTR [esi-8]
	and	eax, -4					; fffffffcH

; 3464 :         init_top(m, mn, (size_t)((tbase + tsize) - (char*)mn) -TOP_FOOT_SIZE);

	lea	edx, DWORD PTR [ebx-40]
	add	ecx, eax
	sub	edi, ecx

; 3186 :   size_t offset = align_offset(chunk2mem(p));

	mov	eax, ecx

; 3464 :         init_top(m, mn, (size_t)((tbase + tsize) - (char*)mn) -TOP_FOOT_SIZE);

	add	edx, edi

; 3186 :   size_t offset = align_offset(chunk2mem(p));

	and	eax, 7
	je	SHORT $LN96@sys_alloc
$LN95@sys_alloc:
	neg	eax
	and	eax, 7
$LN96@sys_alloc:

; 3187 :   p = (mchunkptr)((char*)p + offset);

	add	ecx, eax

; 3188 :   psize -= offset;

	sub	edx, eax

; 3189 : 
; 3190 :   m->top = p;
; 3191 :   m->topsize = psize;
; 3192 :   p->head = psize | PINUSE_BIT;

	mov	eax, edx
	mov	DWORD PTR [esi+24], ecx
	or	eax, 1
	mov	DWORD PTR [esi+12], edx
	mov	DWORD PTR [ecx+4], eax

; 3193 :   /* set size of fake trailing chunk holding overhead space only once */
; 3194 :   chunk_plus_offset(p, psize)->head = TOP_FOOT_SIZE;
; 3195 :   m->trim_check = mparams.trim_threshold; /* reset on each update */

	mov	eax, DWORD PTR _mparams+16
	mov	DWORD PTR [ecx+edx+4], 40		; 00000028H
	mov	DWORD PTR [esi+28], eax

; 3465 :       }
; 3466 :     }

	jmp	SHORT $LN40@sys_alloc
$LN32@sys_alloc:

; 3467 : 
; 3468 :     else {
; 3469 :       /* Try to merge with an existing segment */
; 3470 :       msegmentptr sp = &m->seg;

	mov	ecx, eax

; 3471 :       while (sp != 0 && tbase != sp->base + sp->size)

	test	ecx, ecx
	je	SHORT $LN36@sys_alloc
$LL2@sys_alloc:
	mov	ebp, DWORD PTR [ecx+4]
	mov	edx, DWORD PTR [ecx]
	add	ebp, edx
	mov	DWORD PTR tv1094[esp+24], ebp
	cmp	edi, ebp
	mov	ebp, DWORD PTR _nb$1$[esp+24]
	je	SHORT $LN3@sys_alloc

; 3472 :         sp = sp->next;

	mov	ecx, DWORD PTR [ecx+8]
	test	ecx, ecx
	jne	SHORT $LL2@sys_alloc
$LN36@sys_alloc:

; 3480 :       else {
; 3481 :         if (tbase < m->least_addr)

	cmp	edi, DWORD PTR [esi+16]
	jae	SHORT $LN38@sys_alloc

; 3482 :           m->least_addr = tbase;

	mov	DWORD PTR [esi+16], edi
$LN38@sys_alloc:

; 3483 :         sp = &m->seg;
; 3484 :         while (sp != 0 && sp->base != tbase + tsize)

	test	eax, eax
	je	SHORT $LN39@sys_alloc
	lea	edx, DWORD PTR [edi+ebx]
	npad	2
$LL4@sys_alloc:
	mov	ecx, DWORD PTR [eax]
	cmp	ecx, edx
	je	$LN5@sys_alloc

; 3485 :           sp = sp->next;

	mov	eax, DWORD PTR [eax+8]
	test	eax, eax
	jne	SHORT $LL4@sys_alloc
$LN39@sys_alloc:

; 3493 :         }
; 3494 :         else
; 3495 :           add_segment(m, tbase, tsize, mmap_flag);

	push	1
	push	ebx
	mov	edx, edi
	mov	ecx, esi
	call	_add_segment
	add	esp, 8
$LN40@sys_alloc:

; 3496 :       }
; 3497 :     }
; 3498 : 
; 3499 :     if (nb < m->topsize) { /* Allocate from new or extended top space */

	mov	edx, DWORD PTR [esi+12]
	cmp	ebp, edx
	jae	$LN41@sys_alloc

; 3500 :       size_t rsize = m->topsize -= nb;
; 3501 :       mchunkptr p = m->top;

	mov	ecx, DWORD PTR [esi+24]
	sub	edx, ebp
	mov	DWORD PTR [esi+12], edx

; 3502 :       mchunkptr r = m->top = chunk_plus_offset(p, nb);
; 3503 :       r->head = rsize | PINUSE_BIT;

	or	edx, 1
	pop	edi
	lea	eax, DWORD PTR [ecx+ebp]

; 3504 :       set_size_and_pinuse_of_inuse_chunk(m, p, nb);

	or	ebp, 3
	mov	DWORD PTR [esi+24], eax
	mov	DWORD PTR [eax+4], edx

; 3505 :       check_top_chunk(m, m->top);
; 3506 :       check_malloced_chunk(m, chunk2mem(p), nb);
; 3507 :       return chunk2mem(p);

	lea	eax, DWORD PTR [ecx+8]

; 3513 : }

	pop	esi
	mov	DWORD PTR [ecx+4], ebp
	pop	ebp
	pop	ebx
	add	esp, 8
	ret	0
$LN3@sys_alloc:

; 3473 :       if (sp != 0 &&
; 3474 :           !is_extern_segment(sp) &&
; 3475 :           (sp->sflags & IS_MMAPPED_BIT) == mmap_flag &&

	test	BYTE PTR [ecx+12], 8
	jne	SHORT $LN36@sys_alloc
	test	BYTE PTR [ecx+12], 1
	je	SHORT $LN36@sys_alloc
	cmp	DWORD PTR [esi+24], edx
	jb	SHORT $LN36@sys_alloc
	mov	edx, DWORD PTR [esi+24]
	cmp	edx, DWORD PTR tv1094[esp+24]
	jae	SHORT $LN36@sys_alloc

; 3476 :           segment_holds(sp, m->top)) { /* append */
; 3477 :         sp->size += tsize;

	add	DWORD PTR [ecx+4], ebx

; 3478 :         init_top(m, m->top, m->topsize + tsize);

	mov	ecx, DWORD PTR [esi+12]
	mov	edx, DWORD PTR [esi+24]
	add	ecx, ebx

; 3186 :   size_t offset = align_offset(chunk2mem(p));

	mov	eax, edx
	and	eax, 7
	je	SHORT $LN102@sys_alloc
$LN101@sys_alloc:
	neg	eax
	and	eax, 7
$LN102@sys_alloc:

; 3187 :   p = (mchunkptr)((char*)p + offset);

	add	edx, eax

; 3188 :   psize -= offset;

	sub	ecx, eax

; 3189 : 
; 3190 :   m->top = p;
; 3191 :   m->topsize = psize;
; 3192 :   p->head = psize | PINUSE_BIT;

	mov	eax, ecx
	mov	DWORD PTR [esi+24], edx
	or	eax, 1
	mov	DWORD PTR [esi+12], ecx
	mov	DWORD PTR [edx+4], eax

; 3193 :   /* set size of fake trailing chunk holding overhead space only once */
; 3194 :   chunk_plus_offset(p, psize)->head = TOP_FOOT_SIZE;
; 3195 :   m->trim_check = mparams.trim_threshold; /* reset on each update */

	mov	eax, DWORD PTR _mparams+16
	mov	DWORD PTR [edx+ecx+4], 40		; 00000028H
	mov	DWORD PTR [esi+28], eax

; 3479 :       }

	jmp	$LN40@sys_alloc
$LN5@sys_alloc:

; 3486 :         if (sp != 0 &&
; 3487 :             !is_extern_segment(sp) &&

	mov	edx, DWORD PTR [eax+12]
	test	dl, 8
	jne	$LN39@sys_alloc
	test	dl, 1
	je	$LN39@sys_alloc

; 3488 :             (sp->sflags & IS_MMAPPED_BIT) == mmap_flag) {
; 3489 :           char* oldbase = sp->base;
; 3490 :           sp->base = tbase;
; 3491 :           sp->size += tsize;

	add	DWORD PTR [eax+4], ebx

; 3492 :           return prepend_alloc(m, tbase, oldbase, nb);

	mov	edx, edi
	push	ebp
	push	ecx
	mov	ecx, esi
	mov	DWORD PTR [eax], edi
	call	_prepend_alloc
	add	esp, 8
	pop	edi

; 3513 : }

	pop	esi
	pop	ebp
	pop	ebx
	add	esp, 8
	ret	0
$LN41@sys_alloc:

; 3508 :     }
; 3509 :   }
; 3510 : 
; 3511 :   MALLOC_FAILURE_ACTION;
; 3512 :   return 0;

	xor	eax, eax
$LN1@sys_alloc:
	pop	edi

; 3513 : }

	pop	esi
	pop	ebp
	pop	ebx
	add	esp, 8
	ret	0
_sys_alloc ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_released$1$ = -28					; size = 4
_sp$1$ = -24						; size = 4
_size$1$ = -20						; size = 4
_pred$1$ = -16						; size = 4
_next$1$ = -12						; size = 4
_XP$1$ = -8						; size = 4
_base$1$ = -4						; size = 4
_release_unused_segments PROC
; _m$ = ecx

; 3518 : static size_t release_unused_segments(mstate m) {

	sub	esp, 28					; 0000001cH
	push	ebx
	push	ebp
	push	esi
	push	edi
	mov	edi, ecx

; 3519 :   size_t released = 0;

	xor	ebp, ebp

; 3520 :   msegmentptr pred = &m->seg;
; 3521 :   msegmentptr sp = pred->next;

	mov	eax, DWORD PTR [edi+448]
	lea	edx, DWORD PTR [edi+440]
	mov	DWORD PTR _released$1$[esp+44], ebp
	mov	DWORD PTR _pred$1$[esp+44], edx
	mov	DWORD PTR _sp$1$[esp+44], eax

; 3522 :   while (sp != 0) {

	test	eax, eax
	je	$LN84@release_un
	npad	5
$LL2@release_un:

; 3523 :     char* base = sp->base;

	mov	ecx, DWORD PTR [eax]

; 3524 :     size_t size = sp->size;

	mov	ebx, DWORD PTR [eax+4]

; 3525 :     msegmentptr next = sp->next;

	mov	edx, DWORD PTR [eax+8]
	mov	eax, DWORD PTR [eax+12]
	and	al, 9
	mov	DWORD PTR _base$1$[esp+44], ecx
	mov	DWORD PTR _size$1$[esp+44], ebx
	mov	DWORD PTR _next$1$[esp+44], edx
	cmp	al, 1

; 3526 :     if (is_mmapped_segment(sp) && !is_extern_segment(sp)) {

	jne	$LN93@release_un

; 3527 :       mchunkptr p = align_as_chunk(base);

	mov	eax, ecx
	and	eax, 7
	je	SHORT $LN57@release_un
$LN56@release_un:
	neg	eax
	and	eax, 7
$LN57@release_un:
	lea	esi, DWORD PTR [eax+ecx]

; 3528 :       size_t psize = chunksize(p);

	mov	eax, DWORD PTR [esi+4]
	mov	ebp, eax
	and	ebp, -4					; fffffffcH

; 3529 :       /* Can unmap if first chunk holds entire segment and not pinned */
; 3530 :       if (!cinuse(p) && (char*)p + psize >= base + size - TOP_FOOT_SIZE) {

	test	al, 2
	jne	$LN95@release_un
	add	ecx, -40				; ffffffd8H
	lea	eax, DWORD PTR [esi+ebp]
	add	ecx, ebx
	cmp	eax, ecx
	jb	$LN95@release_un

; 3531 :         tchunkptr tp = (tchunkptr)p;
; 3532 :         assert(segment_holds(sp, (char*)sp));
; 3533 :         if (p == m->dv) {

	cmp	esi, DWORD PTR [edi+20]
	jne	SHORT $LN11@release_un

; 3534 :           m->dv = 0;

	mov	DWORD PTR [edi+20], 0

; 3535 :           m->dvsize = 0;

	mov	DWORD PTR [edi+8], 0

; 3536 :         }

	jmp	$LN38@release_un
$LN11@release_un:

; 3537 :         else {
; 3538 :           unlink_large_chunk(m, tp);

	mov	ecx, DWORD PTR [esi+12]
	mov	edx, DWORD PTR [esi+24]
	mov	DWORD PTR _XP$1$[esp+44], edx
	cmp	ecx, esi
	je	SHORT $LN13@release_un
	mov	eax, DWORD PTR [esi+8]
	cmp	eax, DWORD PTR [edi+16]
	jb	$LN20@release_un
	mov	DWORD PTR [eax+12], ecx
	mov	DWORD PTR [ecx+8], eax
	jmp	SHORT $LN21@release_un
$LN13@release_un:
	mov	ecx, DWORD PTR [esi+20]
	lea	ebx, DWORD PTR [esi+20]
	test	ecx, ecx
	jne	SHORT $LL4@release_un
	mov	ecx, DWORD PTR [esi+16]
	lea	ebx, DWORD PTR [esi+16]
	test	ecx, ecx
	je	SHORT $LN96@release_un
	npad	2
$LL4@release_un:
	mov	edx, DWORD PTR [ecx+20]
	lea	eax, DWORD PTR [ecx+20]
	test	edx, edx
	jne	SHORT $LN19@release_un
	mov	edx, DWORD PTR [ecx+16]
	lea	eax, DWORD PTR [ecx+16]
	test	edx, edx
	je	SHORT $LN5@release_un
$LN19@release_un:
	mov	ebx, eax
	mov	ecx, edx
	jmp	SHORT $LL4@release_un
$LN5@release_un:
	cmp	ebx, DWORD PTR [edi+16]
	jb	$LN20@release_un
	mov	edx, DWORD PTR _XP$1$[esp+44]
	mov	DWORD PTR [ebx], 0
$LN96@release_un:
	mov	ebx, DWORD PTR _size$1$[esp+44]
$LN21@release_un:
	test	edx, edx
	je	SHORT $LN38@release_un
	mov	eax, DWORD PTR [esi+28]
	cmp	esi, DWORD PTR [edi+eax*4+300]
	jne	SHORT $LN23@release_un
	mov	DWORD PTR [edi+eax*4+300], ecx
	test	ecx, ecx
	jne	SHORT $LN77@release_un
	mov	ecx, DWORD PTR [edi+4]
	mov	eax, DWORD PTR [esi+28]
	btr	ecx, eax
	mov	DWORD PTR [edi+4], ecx
	jmp	SHORT $LN38@release_un
$LN23@release_un:
	cmp	edx, DWORD PTR [edi+16]
	jb	$LN20@release_un
	cmp	DWORD PTR [edx+16], esi
	jne	SHORT $LN28@release_un
	mov	DWORD PTR [edx+16], ecx
	jmp	SHORT $LN29@release_un
$LN28@release_un:
	mov	DWORD PTR [edx+20], ecx
$LN29@release_un:
	test	ecx, ecx
	je	SHORT $LN38@release_un
$LN77@release_un:
	cmp	ecx, DWORD PTR [edi+16]
	jb	$LN20@release_un
	mov	DWORD PTR [ecx+24], edx
	mov	eax, DWORD PTR [esi+16]
	test	eax, eax
	je	SHORT $LN35@release_un
	cmp	eax, DWORD PTR [edi+16]
	jb	$LN20@release_un
	mov	DWORD PTR [ecx+16], eax
	mov	DWORD PTR [eax+24], ecx
$LN35@release_un:
	mov	eax, DWORD PTR [esi+20]
	test	eax, eax
	je	SHORT $LN38@release_un
	cmp	eax, DWORD PTR [edi+16]
	jb	$LN20@release_un
	mov	DWORD PTR [ecx+20], eax
	mov	DWORD PTR [eax+24], ecx
$LN38@release_un:

; 3539 :         }
; 3540 :         if (CALL_MUNMAP(base, size) == 0) {

	mov	ecx, DWORD PTR _base$1$[esp+44]
	mov	edx, ebx
	call	_win32munmap
	test	eax, eax
	jne	SHORT $LN39@release_un

; 3541 :           released += size;
; 3542 :           m->footprint -= size;
; 3543 :           /* unlink obsoleted record */
; 3544 :           sp = pred;

	mov	ecx, DWORD PTR _pred$1$[esp+44]
	mov	eax, ecx
	mov	ebp, DWORD PTR _released$1$[esp+44]

; 3545 :           sp->next = next;

	mov	edx, DWORD PTR _next$1$[esp+44]
	add	ebp, ebx
	sub	DWORD PTR [edi+428], ebx
	mov	DWORD PTR _released$1$[esp+44], ebp
	mov	DWORD PTR [ecx+8], edx

; 3546 :         }

	jmp	$LN7@release_un
$LN39@release_un:

; 3547 :         else { /* back out if cannot unmap */
; 3548 :           insert_large_chunk(m, tp, psize);

	mov	edx, ebp
	shr	edx, 8
	test	edx, edx
	jne	SHORT $LN41@release_un
	xor	ecx, ecx
	jmp	SHORT $LN44@release_un
$LN41@release_un:
	cmp	edx, 65535				; 0000ffffH
	jbe	SHORT $LN43@release_un
	mov	ecx, 31					; 0000001fH
	jmp	SHORT $LN44@release_un
$LN43@release_un:
	lea	eax, DWORD PTR [edx-256]
	shr	eax, 16					; 00000010H
	and	eax, 8
	mov	ecx, eax
	shl	edx, cl
	lea	ecx, DWORD PTR [edx-4096]
	shr	ecx, 16					; 00000010H
	and	ecx, 4
	shl	edx, cl
	add	eax, ecx
	lea	ecx, DWORD PTR [edx-16384]
	shr	ecx, 16					; 00000010H
	and	ecx, 2
	shl	edx, cl
	shr	edx, 15					; 0000000fH
	sub	edx, ecx
	sub	edx, eax
	mov	eax, ebp
	lea	ecx, DWORD PTR [edx+21]
	shr	eax, cl
	lea	ecx, DWORD PTR [edx+14]
	and	eax, 1
	lea	ecx, DWORD PTR [eax+ecx*2]
$LN44@release_un:
	mov	eax, 1
	mov	DWORD PTR [esi+28], ecx
	mov	DWORD PTR [esi+20], 0
	lea	ebx, DWORD PTR [edi+300]
	mov	DWORD PTR [esi+16], 0
	lea	ebx, DWORD PTR [ebx+ecx*4]
	mov	edx, DWORD PTR [edi+4]
	shl	eax, cl
	test	eax, edx
	jne	SHORT $LN45@release_un
	bts	edx, ecx
	mov	DWORD PTR [edi+4], edx
	mov	DWORD PTR [ebx], esi
	mov	DWORD PTR [esi+24], ebx
	mov	DWORD PTR [esi+12], esi
	mov	DWORD PTR [esi+8], esi
	jmp	SHORT $LN95@release_un
$LN45@release_un:
	mov	edx, DWORD PTR [ebx]
	cmp	ecx, 31					; 0000001fH
	jne	SHORT $LN60@release_un
	xor	eax, eax
	jmp	SHORT $LN61@release_un
$LN60@release_un:
	shr	ecx, 1
	mov	eax, 25					; 00000019H
	sub	eax, ecx
$LN61@release_un:
	mov	ecx, eax
	mov	ebx, ebp
	mov	eax, DWORD PTR [edx+4]
	and	eax, -4					; fffffffcH
	shl	ebx, cl
	cmp	eax, ebp
	je	SHORT $LN47@release_un
	npad	3
$LL6@release_un:
	mov	eax, ebx
	add	ebx, ebx
	shr	eax, 31					; 0000001fH
	add	eax, 4
	lea	ecx, DWORD PTR [edx+eax*4]
	mov	eax, DWORD PTR [ecx]
	test	eax, eax
	je	SHORT $LN49@release_un
	mov	edx, eax
	mov	eax, DWORD PTR [edx+4]
	and	eax, -4					; fffffffcH
	cmp	eax, ebp
	jne	SHORT $LL6@release_un
$LN47@release_un:
	mov	ecx, DWORD PTR [edi+16]
	cmp	edx, ecx
	jb	SHORT $LN20@release_un
	mov	eax, DWORD PTR [edx+8]
	cmp	eax, ecx
	jb	SHORT $LN20@release_un
	mov	DWORD PTR [eax+12], esi
	mov	DWORD PTR [edx+8], esi
	mov	DWORD PTR [esi+8], eax
	mov	DWORD PTR [esi+12], edx
	mov	DWORD PTR [esi+24], 0
$LN95@release_un:

; 3549 :         }
; 3550 :       }
; 3551 :     }
; 3552 :     pred = sp;

	mov	ebp, DWORD PTR _released$1$[esp+44]
$LN93@release_un:
	mov	eax, DWORD PTR _sp$1$[esp+44]
$LN7@release_un:

; 3553 :     sp = next;

	mov	ecx, DWORD PTR _next$1$[esp+44]
	mov	DWORD PTR _pred$1$[esp+44], eax
	mov	eax, ecx
	mov	DWORD PTR _sp$1$[esp+44], ecx
	test	ecx, ecx
	jne	$LL2@release_un
$LN84@release_un:
	pop	edi

; 3554 :   }
; 3555 :   return released;
; 3556 : }

	pop	esi
	mov	eax, ebp
	pop	ebp
	pop	ebx
	add	esp, 28					; 0000001cH
	ret	0
$LN49@release_un:

; 3547 :         else { /* back out if cannot unmap */
; 3548 :           insert_large_chunk(m, tp, psize);

	cmp	ecx, DWORD PTR [edi+16]
	jb	SHORT $LN20@release_un
	mov	DWORD PTR [ecx], esi
	mov	DWORD PTR [esi+24], edx
	mov	DWORD PTR [esi+12], esi
	mov	DWORD PTR [esi+8], esi
	jmp	SHORT $LN95@release_un
$LN20@release_un:

; 3537 :         else {
; 3538 :           unlink_large_chunk(m, tp);

	call	DWORD PTR __imp__abort
$LN99@release_un:
	int	3
_release_unused_segments ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_sp$1$ = -4						; size = 4
_sys_trim PROC
; _m$ = ecx
; _pad$dead$ = edx

; 3558 : static int sys_trim(mstate m, size_t pad) {

	push	ecx
	push	ebx
	push	ebp
	push	esi
	mov	esi, ecx

; 3559 :   size_t released = 0;

	xor	ebp, ebp

; 3560 :   if (pad < MAX_REQUEST && is_initialized(m)) {

	mov	ebx, DWORD PTR [esi+24]
	test	ebx, ebx
	je	$LN16@sys_trim

; 3561 :     pad += TOP_FOOT_SIZE; /* ensure enough room for segment overhead */
; 3562 : 
; 3563 :     if (m->topsize > pad) {

	mov	eax, DWORD PTR [esi+12]
	cmp	eax, 40					; 00000028H
	jbe	$LN27@sys_trim

; 3564 :       /* Shrink top space in granularity-size units, keeping at least one */
; 3565 :       size_t unit = mparams.granularity;
; 3566 :       size_t extra = ((m->topsize - pad + (unit - SIZE_T_ONE)) / unit -

	mov	ecx, DWORD PTR _mparams+8
	xor	edx, edx
	push	edi
	lea	edi, DWORD PTR [ecx-41]
	add	edi, eax
	mov	eax, edi
	div	ecx
	sub	edi, edx

; 3567 :                       SIZE_T_ONE) * unit;
; 3568 :       msegmentptr sp = segment_holding(m, (char*)m->top);

	mov	edx, ebx
	sub	edi, ecx
	mov	ecx, esi
	call	_segment_holding
	mov	DWORD PTR _sp$1$[esp+20], eax

; 3569 : 
; 3570 :       if (!is_extern_segment(sp)) {

	mov	ecx, DWORD PTR [eax+12]
	test	cl, 8
	jne	$LN40@sys_trim

; 3571 :         if (is_mmapped_segment(sp)) {

	test	cl, 1
	je	SHORT $LN40@sys_trim

; 3572 :           if (HAVE_MMAP &&
; 3573 :               sp->size >= extra &&

	mov	ebx, DWORD PTR [eax+4]
	cmp	ebx, edi
	jb	SHORT $LN40@sys_trim

; 2079 :     if ((char*)sp >= ss->base && (char*)sp < ss->base + ss->size)

	mov	ecx, DWORD PTR [eax]
	lea	edx, DWORD PTR [esi+440]
$LL21@sys_trim:
	cmp	edx, ecx
	jb	SHORT $LN37@sys_trim
	lea	eax, DWORD PTR [ebx+ecx]
	cmp	edx, eax
	jb	SHORT $LN40@sys_trim
$LN37@sys_trim:

; 2080 :       return 1;
; 2081 :     if ((sp = sp->next) == 0)

	mov	edx, DWORD PTR [edx+8]
	test	edx, edx
	jne	SHORT $LL21@sys_trim

; 3574 :               !has_segment_link(m, sp)) { /* can't shrink if pinned */
; 3575 :             size_t newsize = sp->size - extra;
; 3576 :             /* Prefer mremap, fall back to munmap */
; 3577 :             if ((CALL_MREMAP(sp->base, sp->size, newsize, 0) != MFAIL) ||

	sub	ecx, edi
	mov	edx, edi
	add	ecx, ebx
	call	_win32munmap
	test	eax, eax
	jne	SHORT $LN40@sys_trim

; 3578 :                 (CALL_MUNMAP(sp->base + newsize, extra) == 0)) {
; 3579 :               released = extra;

	mov	ebp, edi

; 3580 :             }
; 3581 :           }
; 3582 :         }
; 3583 :         else if (HAVE_MORECORE) {
; 3584 :           if (extra >= HALF_MAX_SIZE_T) /* Avoid wrapping negative */
; 3585 :             extra = (HALF_MAX_SIZE_T) + SIZE_T_ONE - unit;
; 3586 :           ACQUIRE_MORECORE_LOCK();
; 3587 :           {
; 3588 :             /* Make sure end of memory is where we last set it. */
; 3589 :             char* old_br = (char*)(CALL_MORECORE(0));
; 3590 :             if (old_br == sp->base + sp->size) {
; 3591 :               char* rel_br = (char*)(CALL_MORECORE(-extra));
; 3592 :               char* new_br = (char*)(CALL_MORECORE(0));
; 3593 :               if (rel_br != CMFAIL && new_br < old_br)
; 3594 :                 released = old_br - new_br;
; 3595 :             }
; 3596 :           }
; 3597 :           RELEASE_MORECORE_LOCK();
; 3598 :         }
; 3599 :       }
; 3600 : 
; 3601 :       if (released != 0) {

	test	edi, edi
	je	SHORT $LN40@sys_trim

; 3602 :         sp->size -= released;

	mov	eax, DWORD PTR _sp$1$[esp+20]
	sub	DWORD PTR [eax+4], edi

; 3603 :         m->footprint -= released;
; 3604 :         init_top(m, m->top, m->topsize - released);

	mov	ecx, DWORD PTR [esi+12]
	mov	edx, DWORD PTR [esi+24]
	sub	ecx, edi
	sub	DWORD PTR [esi+428], edi

; 3186 :   size_t offset = align_offset(chunk2mem(p));

	mov	eax, edx
	and	eax, 7
	je	SHORT $LN30@sys_trim
$LN29@sys_trim:
	neg	eax
	and	eax, 7
$LN30@sys_trim:

; 3187 :   p = (mchunkptr)((char*)p + offset);

	add	edx, eax

; 3188 :   psize -= offset;

	sub	ecx, eax

; 3189 : 
; 3190 :   m->top = p;
; 3191 :   m->topsize = psize;
; 3192 :   p->head = psize | PINUSE_BIT;

	mov	eax, ecx
	mov	DWORD PTR [esi+24], edx
	or	eax, 1
	mov	DWORD PTR [esi+12], ecx
	mov	DWORD PTR [edx+4], eax

; 3193 :   /* set size of fake trailing chunk holding overhead space only once */
; 3194 :   chunk_plus_offset(p, psize)->head = TOP_FOOT_SIZE;
; 3195 :   m->trim_check = mparams.trim_threshold; /* reset on each update */

	mov	eax, DWORD PTR _mparams+16
	mov	DWORD PTR [edx+ecx+4], 40		; 00000028H
	mov	DWORD PTR [esi+28], eax
$LN40@sys_trim:
	pop	edi
$LN27@sys_trim:

; 3605 :         check_top_chunk(m, m->top);
; 3606 :       }
; 3607 :     }
; 3608 : 
; 3609 :     /* Unmap any unused mmapped segments */
; 3610 :     if (HAVE_MMAP) 
; 3611 :       released += release_unused_segments(m);

	mov	ecx, esi
	call	_release_unused_segments
	add	ebp, eax

; 3612 : 
; 3613 :     /* On failure, disable autotrim to avoid repeated failed future calls */
; 3614 :     if (released == 0)

	jne	SHORT $LN16@sys_trim

; 3615 :       m->trim_check = MAX_SIZE_T;

	mov	DWORD PTR [esi+28], -1
$LN16@sys_trim:

; 3616 :   }
; 3617 : 
; 3618 :   return (released != 0)? 1 : 0;

	xor	eax, eax
	test	ebp, ebp
	pop	esi
	pop	ebp
	setne	al
	pop	ebx

; 3619 : }

	pop	ecx
	ret	0
_sys_trim ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_RP$1$ = -24						; size = 4
_sizebits$1$ = -24					; size = 4
_XP$1$ = -20						; size = 4
_idx$1$ = -20						; size = 4
tv1231 = -16						; size = 4
_nb$1$ = -16						; size = 4
_r$1$ = -12						; size = 4
tv1292 = -12						; size = 4
tv1294 = -8						; size = 4
_C$1$ = -4						; size = 4
_K$1$ = -4						; size = 4
tv1295 = -4						; size = 4
tv1293 = -4						; size = 4
_rt$1$ = -4						; size = 4
_tmalloc_large PROC
; _m$ = ecx
; _nb$ = edx

; 3624 : static void* tmalloc_large(mstate m, size_t nb) {

	sub	esp, 24					; 00000018H
	push	ebx
	push	ebp
	mov	ebx, edx
	mov	ebp, ecx
	push	esi

; 3625 :   tchunkptr v = 0;
; 3626 :   size_t rsize = -nb; /* Unsigned negation */

	mov	esi, ebx

; 3627 :   tchunkptr t;
; 3628 :   bindex_t idx;
; 3629 :   compute_tree_index(nb, idx);

	shr	edx, 8
	push	edi
	xor	edi, edi
	mov	DWORD PTR _nb$1$[esp+40], ebx
	neg	esi
	test	edx, edx
	jne	SHORT $LN12@tmalloc_la
	xor	eax, eax
	jmp	SHORT $LN134@tmalloc_la
$LN12@tmalloc_la:
	cmp	edx, 65535				; 0000ffffH
	jbe	SHORT $LN14@tmalloc_la
	mov	eax, 31					; 0000001fH
	jmp	SHORT $LN134@tmalloc_la
$LN14@tmalloc_la:
	lea	eax, DWORD PTR [edx-256]
	shr	eax, 16					; 00000010H
	and	eax, 8
	mov	ecx, eax
	shl	edx, cl
	lea	ecx, DWORD PTR [edx-4096]
	shr	ecx, 16					; 00000010H
	and	ecx, 4
	shl	edx, cl
	add	eax, ecx
	lea	ecx, DWORD PTR [edx-16384]
	shr	ecx, 16					; 00000010H
	and	ecx, 2
	shl	edx, cl
	shr	edx, 15					; 0000000fH
	sub	edx, ecx
	sub	edx, eax
	mov	eax, ebx
	lea	ecx, DWORD PTR [edx+21]
	shr	eax, cl
	and	eax, 1
	lea	eax, DWORD PTR [eax+edx*2]
	add	eax, 28					; 0000001cH
$LN134@tmalloc_la:

; 3630 : 
; 3631 :   if ((t = *treebin_at(m, idx)) != 0) {

	mov	edx, DWORD PTR [ebp+eax*4+300]
	mov	DWORD PTR _idx$1$[esp+40], eax
	test	edx, edx
	je	$LN108@tmalloc_la

; 3632 :     /* Traverse tree for this bin looking for node with size == nb */
; 3633 :     size_t sizebits = nb << leftshift_for_tree_index(idx);

	cmp	eax, 31					; 0000001fH
	jne	SHORT $LN76@tmalloc_la
	xor	ecx, ecx
	jmp	SHORT $LN77@tmalloc_la
$LN76@tmalloc_la:
	shr	eax, 1
	mov	ecx, 25					; 00000019H
	sub	ecx, eax
$LN77@tmalloc_la:
	mov	eax, ebx
	shl	eax, cl

; 3634 :     tchunkptr rst = 0;  /* The deepest untaken right subtree */

	xor	ecx, ecx
	mov	DWORD PTR _sizebits$1$[esp+40], eax
$LL2@tmalloc_la:

; 3635 :     for (;;) {
; 3636 :       tchunkptr rt;
; 3637 :       size_t trem = chunksize(t) - nb;

	mov	eax, DWORD PTR [edx+4]
	and	eax, -4					; fffffffcH
	mov	DWORD PTR tv1292[esp+40], esi
	sub	eax, ebx
	mov	DWORD PTR tv1293[esp+40], edi
	mov	DWORD PTR tv1294[esp+40], esi

; 3638 :       if (trem < rsize) {

	cmp	eax, esi
	jae	SHORT $LN18@tmalloc_la

; 3639 :         v = t;

	mov	edi, edx

; 3640 :         if ((rsize = trem) == 0)

	mov	esi, eax
	test	eax, eax
	je	SHORT $LN3@tmalloc_la
$LN18@tmalloc_la:

; 3641 :           break;
; 3642 :       }
; 3643 :       rt = t->child[1];

	cmp	eax, DWORD PTR tv1292[esp+40]
	mov	esi, eax
	mov	edi, edx
	cmovae	esi, DWORD PTR tv1292[esp+40]
	cmp	eax, DWORD PTR tv1294[esp+40]
	mov	eax, DWORD PTR [edx+20]
	cmovae	edi, DWORD PTR tv1293[esp+40]
	mov	DWORD PTR _rt$1$[esp+40], eax

; 3644 :       t = t->child[(sizebits >> (SIZE_T_BITSIZE-SIZE_T_ONE)) & 1];

	mov	eax, DWORD PTR _sizebits$1$[esp+40]
	shr	eax, 31					; 0000001fH
	mov	edx, DWORD PTR [edx+eax*4+16]

; 3645 :       if (rt != 0 && rt != t)

	mov	eax, DWORD PTR _rt$1$[esp+40]
	test	eax, eax
	je	SHORT $LN19@tmalloc_la
	cmp	eax, edx
	cmovne	ecx, eax
$LN19@tmalloc_la:

; 3646 :         rst = rt;
; 3647 :       if (t == 0) {

	test	edx, edx
	je	SHORT $LN87@tmalloc_la

; 3649 :         break;
; 3650 :       }
; 3651 :       sizebits <<= 1;

	shl	DWORD PTR _sizebits$1$[esp+40], 1

; 3652 :     }

	jmp	SHORT $LL2@tmalloc_la
$LN87@tmalloc_la:

; 3648 :         t = rst; /* set t to least subtree holding sizes > nb */

	mov	edx, ecx
$LN3@tmalloc_la:

; 3653 :   }
; 3654 : 
; 3655 :   if (t == 0 && v == 0) { /* set t to root of next non-empty treebin */

	test	edx, edx
	jne	SHORT $LN5@tmalloc_la
	test	edi, edi
	jne	$LN112@tmalloc_la
$LN108@tmalloc_la:

; 3656 :     binmap_t leftbits = left_bits(idx2bit(idx)) & m->treemap;

	mov	ecx, DWORD PTR _idx$1$[esp+40]
	mov	eax, -2					; fffffffeH
	shl	eax, cl
	and	eax, DWORD PTR [ebp+4]

; 3657 :     if (leftbits != 0) {

	je	$LN24@tmalloc_la

; 3658 :       bindex_t i;
; 3659 :       binmap_t leastbit = least_bit(leftbits);

	mov	edx, eax
	neg	edx
	and	edx, eax

; 3660 :       compute_bit2idx(leastbit, i);

	dec	edx
	mov	eax, edx
	shr	eax, 12					; 0000000cH
	and	eax, 16					; 00000010H
	mov	ecx, eax
	shr	edx, cl
	mov	ecx, edx
	shr	ecx, 5
	and	ecx, 8
	shr	edx, cl
	add	eax, ecx
	mov	ecx, edx
	shr	ecx, 2
	and	ecx, 4
	shr	edx, cl
	add	eax, ecx
	mov	ecx, edx
	shr	ecx, 1
	and	ecx, 2
	shr	edx, cl
	add	eax, ecx
	mov	ecx, edx
	shr	ecx, 1
	and	ecx, 1
	shr	edx, cl

; 3661 :       t = *treebin_at(m, i);

	add	edx, eax
	add	edx, ecx
	mov	edx, DWORD PTR [ebp+edx*4+300]

; 3662 :     }
; 3663 :   }
; 3664 : 
; 3665 :   while (t != 0) { /* find smallest of tree or subtree */

	test	edx, edx
	je	SHORT $LN6@tmalloc_la
	jmp	SHORT $LN5@tmalloc_la
$LL131@tmalloc_la:
	mov	ebx, DWORD PTR _nb$1$[esp+40]
$LN5@tmalloc_la:

; 3666 :     size_t trem = chunksize(t) - nb;

	mov	ecx, DWORD PTR [edx+4]

; 3667 :     if (trem < rsize) {
; 3668 :       rsize = trem;
; 3669 :       v = t;
; 3670 :     }
; 3671 :     t = leftmost_child(t);

	mov	eax, edx
	and	ecx, -4					; fffffffcH
	sub	ecx, ebx
	cmp	ecx, esi
	mov	ebx, ecx
	cmovae	eax, edi
	cmovae	ebx, esi
	mov	edi, eax
	mov	eax, DWORD PTR [edx+16]
	test	eax, eax
	je	SHORT $LN78@tmalloc_la
	mov	edx, eax
	jmp	SHORT $LN79@tmalloc_la
$LN78@tmalloc_la:
	mov	edx, DWORD PTR [edx+20]
$LN79@tmalloc_la:

; 3662 :     }
; 3663 :   }
; 3664 : 
; 3665 :   while (t != 0) { /* find smallest of tree or subtree */

	mov	esi, ebx
	test	edx, edx
	jne	SHORT $LL131@tmalloc_la
	mov	ebx, DWORD PTR _nb$1$[esp+40]
$LN6@tmalloc_la:

; 3672 :   }
; 3673 : 
; 3674 :   /*  If dv is a better fit, return 0 so malloc will use it */
; 3675 :   if (v != 0 && rsize < (size_t)(m->dvsize - nb)) {

	test	edi, edi
	je	$LN24@tmalloc_la
$LN112@tmalloc_la:
	mov	eax, DWORD PTR [ebp+8]
	sub	eax, ebx
	cmp	esi, eax
	jae	$LN24@tmalloc_la

; 3676 :     if (RTCHECK(ok_address(m, v))) { /* split */

	cmp	edi, DWORD PTR [ebp+16]
	jb	$LN26@tmalloc_la

; 3677 :       mchunkptr r = chunk_plus_offset(v, nb);

	lea	edx, DWORD PTR [edi+ebx]
	mov	DWORD PTR _r$1$[esp+40], edx

; 3678 :       assert(chunksize(v) == rsize + nb);
; 3679 :       if (RTCHECK(ok_next(v, r))) {

	cmp	edi, edx
	jae	$LN26@tmalloc_la

; 3680 :         unlink_large_chunk(m, v);

	mov	ecx, DWORD PTR [edi+24]
	mov	DWORD PTR _XP$1$[esp+40], ecx
	mov	ecx, DWORD PTR [edi+12]
	cmp	ecx, edi
	je	SHORT $LN27@tmalloc_la
	mov	eax, DWORD PTR [edi+8]
	cmp	eax, DWORD PTR [ebp+16]
	jb	$LN26@tmalloc_la
	mov	DWORD PTR [eax+12], ecx
	mov	DWORD PTR [ecx+8], eax
	jmp	SHORT $LN35@tmalloc_la
$LN27@tmalloc_la:
	mov	ecx, DWORD PTR [edi+20]
	lea	eax, DWORD PTR [edi+20]
	mov	DWORD PTR _RP$1$[esp+40], eax
	test	ecx, ecx
	jne	SHORT $LN129@tmalloc_la
	mov	ecx, DWORD PTR [edi+16]
	lea	eax, DWORD PTR [edi+16]
	mov	DWORD PTR _RP$1$[esp+40], eax
	test	ecx, ecx
	je	SHORT $LN35@tmalloc_la
$LN129@tmalloc_la:
	mov	edx, DWORD PTR _RP$1$[esp+40]
$LL7@tmalloc_la:
	mov	ebx, DWORD PTR [ecx+20]
	lea	eax, DWORD PTR [ecx+20]
	test	ebx, ebx
	jne	SHORT $LN33@tmalloc_la
	mov	ebx, DWORD PTR [ecx+16]
	lea	eax, DWORD PTR [ecx+16]
	test	ebx, ebx
	je	SHORT $LN8@tmalloc_la
$LN33@tmalloc_la:
	mov	edx, eax
	mov	ecx, ebx
	jmp	SHORT $LL7@tmalloc_la
$LN8@tmalloc_la:
	cmp	edx, DWORD PTR [ebp+16]
	mov	DWORD PTR _RP$1$[esp+40], edx
	mov	edx, DWORD PTR _r$1$[esp+40]
	jb	$LN26@tmalloc_la
	mov	eax, DWORD PTR _RP$1$[esp+40]
	mov	ebx, DWORD PTR _nb$1$[esp+40]
	mov	DWORD PTR [eax], 0
$LN35@tmalloc_la:
	cmp	DWORD PTR _XP$1$[esp+40], 0
	je	$LN46@tmalloc_la
	mov	eax, DWORD PTR [edi+28]
	cmp	edi, DWORD PTR [ebp+eax*4+300]
	jne	SHORT $LN37@tmalloc_la
	mov	DWORD PTR [ebp+eax*4+300], ecx
	test	ecx, ecx
	jne	SHORT $LN132@tmalloc_la
	mov	ecx, DWORD PTR [ebp+4]
	mov	eax, DWORD PTR [edi+28]
	btr	ecx, eax
	mov	DWORD PTR [ebp+4], ecx
	jmp	SHORT $LN46@tmalloc_la
$LN37@tmalloc_la:
	mov	eax, DWORD PTR _XP$1$[esp+40]
	cmp	eax, DWORD PTR [ebp+16]
	jb	$LN26@tmalloc_la
	cmp	DWORD PTR [eax+16], edi
	jne	SHORT $LN42@tmalloc_la
	mov	DWORD PTR [eax+16], ecx
	jmp	SHORT $LN43@tmalloc_la
$LN42@tmalloc_la:
	mov	DWORD PTR [eax+20], ecx
$LN43@tmalloc_la:
	test	ecx, ecx
	je	SHORT $LN46@tmalloc_la
	jmp	SHORT $LN102@tmalloc_la
$LN132@tmalloc_la:
	mov	eax, DWORD PTR _XP$1$[esp+40]
$LN102@tmalloc_la:
	cmp	ecx, DWORD PTR [ebp+16]
	jb	$LN26@tmalloc_la
	mov	DWORD PTR [ecx+24], eax
	mov	eax, DWORD PTR [edi+16]
	test	eax, eax
	je	SHORT $LN49@tmalloc_la
	cmp	eax, DWORD PTR [ebp+16]
	jb	$LN26@tmalloc_la
	mov	DWORD PTR [ecx+16], eax
	mov	DWORD PTR [eax+24], ecx
$LN49@tmalloc_la:
	mov	eax, DWORD PTR [edi+20]
	test	eax, eax
	je	SHORT $LN46@tmalloc_la
	cmp	eax, DWORD PTR [ebp+16]
	jb	$LN26@tmalloc_la
	mov	DWORD PTR [ecx+20], eax
	mov	DWORD PTR [eax+24], ecx
$LN46@tmalloc_la:

; 3681 :         if (rsize < MIN_CHUNK_SIZE)

	cmp	esi, 16					; 00000010H
	jae	SHORT $LN53@tmalloc_la

; 3682 :           set_inuse_and_pinuse(m, v, (rsize + nb));

	lea	eax, DWORD PTR [esi+ebx]
	or	eax, 3
	mov	DWORD PTR [edi+4], eax
	lea	eax, DWORD PTR [esi+edi]
	or	DWORD PTR [eax+ebx+4], 1

; 3687 :         }
; 3688 :         return chunk2mem(v);

	lea	eax, DWORD PTR [edi+8]
	pop	edi

; 3692 :   }
; 3693 :   return 0;
; 3694 : }

	pop	esi
	pop	ebp
	pop	ebx
	add	esp, 24					; 00000018H
	ret	0
$LN53@tmalloc_la:

; 3683 :         else {
; 3684 :           set_size_and_pinuse_of_inuse_chunk(m, v, nb);

	or	ebx, 3

; 3685 :           set_size_and_pinuse_of_free_chunk(r, rsize);

	mov	eax, esi

; 3686 :           insert_chunk(m, r, rsize);

	mov	ecx, esi
	mov	DWORD PTR [edi+4], ebx
	or	eax, 1
	shr	ecx, 3
	mov	DWORD PTR [edx+4], eax
	mov	DWORD PTR [edx+esi], esi
	cmp	ecx, 32					; 00000020H
	jae	SHORT $LN55@tmalloc_la
	mov	eax, DWORD PTR [ebp]
	lea	ebx, DWORD PTR [ebp+36]
	mov	edx, DWORD PTR _r$1$[esp+40]
	lea	ebx, DWORD PTR [ebx+ecx*8]
	mov	DWORD PTR tv1231[esp+40], eax
	mov	esi, ebx
	mov	eax, 1
	shl	eax, cl
	test	eax, DWORD PTR tv1231[esp+40]
	jne	SHORT $LN57@tmalloc_la
	mov	eax, DWORD PTR tv1231[esp+40]
	bts	eax, ecx
	mov	DWORD PTR [ebp], eax

; 3687 :         }
; 3688 :         return chunk2mem(v);

	lea	eax, DWORD PTR [edi+8]
	mov	DWORD PTR [ebx+8], edx
	mov	DWORD PTR [esi+12], edx
	pop	edi
	mov	DWORD PTR [edx+8], esi

; 3692 :   }
; 3693 :   return 0;
; 3694 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [edx+12], ebx
	pop	ebx
	add	esp, 24					; 00000018H
	ret	0
$LN57@tmalloc_la:

; 3686 :           insert_chunk(m, r, rsize);

	mov	esi, DWORD PTR [ebx+8]
	cmp	esi, DWORD PTR [ebp+16]
	jb	$LN26@tmalloc_la
	mov	DWORD PTR [ebx+8], edx

; 3687 :         }
; 3688 :         return chunk2mem(v);

	lea	eax, DWORD PTR [edi+8]
	mov	DWORD PTR [esi+12], edx
	pop	edi
	mov	DWORD PTR [edx+8], esi

; 3692 :   }
; 3693 :   return 0;
; 3694 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [edx+12], ebx
	pop	ebx
	add	esp, 24					; 00000018H
	ret	0
$LN55@tmalloc_la:

; 3686 :           insert_chunk(m, r, rsize);

	mov	ebx, esi
	shr	ebx, 8
	test	ebx, ebx
	jne	SHORT $LN61@tmalloc_la
	xor	ecx, ecx
	jmp	SHORT $LN64@tmalloc_la
$LN61@tmalloc_la:
	cmp	ebx, 65535				; 0000ffffH
	jbe	SHORT $LN63@tmalloc_la
	mov	ecx, 31					; 0000001fH
	jmp	SHORT $LN64@tmalloc_la
$LN63@tmalloc_la:
	lea	eax, DWORD PTR [ebx-256]
	shr	eax, 16					; 00000010H
	and	eax, 8
	mov	ecx, eax
	shl	ebx, cl
	lea	ecx, DWORD PTR [ebx-4096]
	shr	ecx, 16					; 00000010H
	and	ecx, 4
	shl	ebx, cl
	add	eax, ecx
	lea	ecx, DWORD PTR [ebx-16384]
	shr	ecx, 16					; 00000010H
	and	ecx, 2
	shl	ebx, cl
	shr	ebx, 15					; 0000000fH
	sub	ebx, ecx
	sub	ebx, eax
	mov	eax, esi
	lea	ecx, DWORD PTR [ebx+21]
	shr	eax, cl
	lea	ecx, DWORD PTR [ebx+14]
	and	eax, 1
	lea	ecx, DWORD PTR [eax+ecx*2]
$LN64@tmalloc_la:
	mov	eax, 1
	mov	DWORD PTR [edx+28], ecx
	mov	DWORD PTR [edx+20], 0
	mov	DWORD PTR [edx+16], 0
	mov	ebx, DWORD PTR [ebp+4]
	shl	eax, cl
	test	eax, ebx
	jne	SHORT $LN65@tmalloc_la
	lea	eax, DWORD PTR [ebp+300]
	bts	ebx, ecx
	mov	DWORD PTR [ebp+4], ebx
	lea	eax, DWORD PTR [eax+ecx*4]
	mov	DWORD PTR [eax], edx
	mov	DWORD PTR [edx+24], eax

; 3687 :         }
; 3688 :         return chunk2mem(v);

	lea	eax, DWORD PTR [edi+8]
	pop	edi

; 3692 :   }
; 3693 :   return 0;
; 3694 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [edx+12], edx
	mov	DWORD PTR [edx+8], edx
	pop	ebx
	add	esp, 24					; 00000018H
	ret	0
$LN65@tmalloc_la:

; 3686 :           insert_chunk(m, r, rsize);

	mov	ebx, DWORD PTR [ebp+ecx*4+300]
	cmp	ecx, 31					; 0000001fH
	jne	SHORT $LN80@tmalloc_la
	xor	ecx, ecx
	jmp	SHORT $LN81@tmalloc_la
$LN80@tmalloc_la:
	shr	ecx, 1
	mov	eax, 25					; 00000019H
	sub	eax, ecx
	mov	DWORD PTR tv1295[esp+40], eax
	mov	ecx, eax
$LN81@tmalloc_la:
	mov	eax, esi
	shl	eax, cl
	mov	DWORD PTR _K$1$[esp+40], eax
	mov	eax, DWORD PTR [ebx+4]
	and	eax, -4					; fffffffcH
	cmp	eax, esi
	je	SHORT $LN67@tmalloc_la
	mov	ecx, DWORD PTR _K$1$[esp+40]
$LL9@tmalloc_la:
	mov	eax, ecx
	add	ecx, ecx
	shr	eax, 31					; 0000001fH
	add	eax, 4
	lea	eax, DWORD PTR [ebx+eax*4]
	mov	DWORD PTR _C$1$[esp+40], eax
	mov	eax, DWORD PTR [eax]
	test	eax, eax
	je	SHORT $LN69@tmalloc_la
	mov	ebx, eax
	mov	eax, DWORD PTR [ebx+4]
	and	eax, -4					; fffffffcH
	cmp	eax, esi
	jne	SHORT $LL9@tmalloc_la
$LN67@tmalloc_la:
	mov	ecx, DWORD PTR [ebp+16]
	cmp	ebx, ecx
	jb	SHORT $LN26@tmalloc_la
	mov	eax, DWORD PTR [ebx+8]
	cmp	eax, ecx
	jb	SHORT $LN26@tmalloc_la
	mov	DWORD PTR [eax+12], edx
	mov	DWORD PTR [ebx+8], edx
	mov	DWORD PTR [edx+8], eax

; 3687 :         }
; 3688 :         return chunk2mem(v);

	lea	eax, DWORD PTR [edi+8]
	pop	edi

; 3692 :   }
; 3693 :   return 0;
; 3694 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [edx+12], ebx
	mov	DWORD PTR [edx+24], 0
	pop	ebx
	add	esp, 24					; 00000018H
	ret	0
$LN69@tmalloc_la:

; 3686 :           insert_chunk(m, r, rsize);

	mov	eax, DWORD PTR _C$1$[esp+40]
	cmp	eax, DWORD PTR [ebp+16]
	jb	SHORT $LN26@tmalloc_la
	mov	DWORD PTR [eax], edx

; 3687 :         }
; 3688 :         return chunk2mem(v);

	lea	eax, DWORD PTR [edi+8]
	pop	edi

; 3692 :   }
; 3693 :   return 0;
; 3694 : }

	pop	esi
	pop	ebp
	mov	DWORD PTR [edx+24], ebx
	mov	DWORD PTR [edx+12], edx
	mov	DWORD PTR [edx+8], edx
	pop	ebx
	add	esp, 24					; 00000018H
	ret	0
$LN26@tmalloc_la:

; 3689 :       }
; 3690 :     }
; 3691 :     CORRUPTION_ERROR_ACTION(m);

	call	DWORD PTR __imp__abort
$LN24@tmalloc_la:
	pop	edi

; 3692 :   }
; 3693 :   return 0;
; 3694 : }

	pop	esi
	pop	ebp
	xor	eax, eax
	pop	ebx
	add	esp, 24					; 00000018H
	ret	0
$LN133@tmalloc_la:
_tmalloc_large ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
tv650 = -16						; size = 4
_nb$1$ = -16						; size = 4
_r$1$ = -12						; size = 4
_XP$1$ = -8						; size = 4
_tmalloc_small PROC
; _m$ = ecx
; _nb$ = edx

; 3697 : static void* tmalloc_small(mstate m, size_t nb) {

	sub	esp, 16					; 00000010H
	push	ebx
	mov	ebx, ecx
	push	ebp
	push	esi
	mov	ebp, edx

; 3698 :   tchunkptr t, v;
; 3699 :   size_t rsize;
; 3700 :   bindex_t i;
; 3701 :   binmap_t leastbit = least_bit(m->treemap);

	mov	esi, DWORD PTR [ebx+4]
	neg	esi
	mov	DWORD PTR _nb$1$[esp+28], ebp
	and	esi, DWORD PTR [ebx+4]

; 3702 :   compute_bit2idx(leastbit, i);

	dec	esi
	mov	eax, esi
	shr	eax, 12					; 0000000cH
	and	eax, 16					; 00000010H
	mov	ecx, eax
	shr	esi, cl
	mov	ecx, esi
	shr	ecx, 5
	and	ecx, 8
	shr	esi, cl
	add	eax, ecx
	mov	ecx, esi
	shr	ecx, 2
	and	ecx, 4
	shr	esi, cl
	add	eax, ecx
	mov	ecx, esi
	shr	ecx, 1
	and	ecx, 2
	shr	esi, cl
	add	eax, ecx
	mov	ecx, esi
	shr	ecx, 1
	and	ecx, 1
	shr	esi, cl

; 3703 : 
; 3704 :   v = t = *treebin_at(m, i);

	add	esi, eax
	add	esi, ecx
	push	edi
	mov	edx, DWORD PTR [ebx+esi*4+300]
	mov	esi, edx

; 3705 :   rsize = chunksize(t) - nb;

	mov	edi, DWORD PTR [edx+4]
	and	edi, -4					; fffffffcH
	sub	edi, ebp
$LL2@tmalloc_sm:

; 3706 : 
; 3707 :   while ((t = leftmost_child(t)) != 0) {

	mov	eax, DWORD PTR [edx+16]
	test	eax, eax
	je	SHORT $LN43@tmalloc_sm
	mov	edx, eax
	jmp	SHORT $LN56@tmalloc_sm
$LN43@tmalloc_sm:
	mov	eax, DWORD PTR [edx+20]
	mov	edx, eax
	test	eax, eax
	je	SHORT $LN3@tmalloc_sm
$LN56@tmalloc_sm:

; 3708 :     size_t trem = chunksize(t) - nb;

	mov	ecx, DWORD PTR [edx+4]

; 3709 :     if (trem < rsize) {
; 3710 :       rsize = trem;
; 3711 :       v = t;
; 3712 :     }
; 3713 :   }

	mov	eax, edx
	and	ecx, -4					; fffffffcH
	sub	ecx, ebp
	cmp	ecx, edi
	cmovae	eax, esi
	cmovae	ecx, edi
	mov	esi, eax
	mov	edi, ecx
	jmp	SHORT $LL2@tmalloc_sm
$LN3@tmalloc_sm:

; 3714 : 
; 3715 :   if (RTCHECK(ok_address(m, v))) {

	cmp	esi, DWORD PTR [ebx+16]
	jb	$LN8@tmalloc_sm

; 3716 :     mchunkptr r = chunk_plus_offset(v, nb);

	lea	eax, DWORD PTR [esi+ebp]
	mov	DWORD PTR _r$1$[esp+32], eax

; 3717 :     assert(chunksize(v) == rsize + nb);
; 3718 :     if (RTCHECK(ok_next(v, r))) {

	cmp	esi, eax
	jae	$LN8@tmalloc_sm

; 3719 :       unlink_large_chunk(m, v);

	mov	eax, DWORD PTR [esi+12]
	mov	edx, DWORD PTR [esi+24]
	mov	DWORD PTR _XP$1$[esp+32], edx
	cmp	eax, esi
	je	SHORT $LN9@tmalloc_sm
	mov	ecx, DWORD PTR [esi+8]
	cmp	ecx, DWORD PTR [ebx+16]
	jb	$LN8@tmalloc_sm
	mov	DWORD PTR [ecx+12], eax
	mov	DWORD PTR [eax+8], ecx
	jmp	SHORT $LN17@tmalloc_sm
$LN9@tmalloc_sm:
	mov	eax, DWORD PTR [esi+20]
	lea	ebp, DWORD PTR [esi+20]
	test	eax, eax
	jne	SHORT $LL4@tmalloc_sm
	mov	eax, DWORD PTR [esi+16]
	lea	ebp, DWORD PTR [esi+16]
	test	eax, eax
	je	SHORT $LN62@tmalloc_sm
	npad	1
$LL4@tmalloc_sm:
	mov	edx, DWORD PTR [eax+20]
	lea	ecx, DWORD PTR [eax+20]
	test	edx, edx
	jne	SHORT $LN15@tmalloc_sm
	mov	edx, DWORD PTR [eax+16]
	lea	ecx, DWORD PTR [eax+16]
	test	edx, edx
	je	SHORT $LN5@tmalloc_sm
$LN15@tmalloc_sm:
	mov	ebp, ecx
	mov	eax, edx
	jmp	SHORT $LL4@tmalloc_sm
$LN5@tmalloc_sm:
	cmp	ebp, DWORD PTR [ebx+16]
	jb	$LN8@tmalloc_sm
	mov	edx, DWORD PTR _XP$1$[esp+32]
	mov	DWORD PTR [ebp], 0
$LN62@tmalloc_sm:
	mov	ebp, DWORD PTR _nb$1$[esp+32]
$LN17@tmalloc_sm:
	test	edx, edx
	je	SHORT $LN28@tmalloc_sm
	mov	ecx, DWORD PTR [esi+28]
	cmp	esi, DWORD PTR [ebx+ecx*4+300]
	jne	SHORT $LN19@tmalloc_sm
	mov	DWORD PTR [ebx+ecx*4+300], eax
	test	eax, eax
	jne	SHORT $LN53@tmalloc_sm
	mov	ecx, DWORD PTR [ebx+4]
	mov	eax, DWORD PTR [esi+28]
	btr	ecx, eax
	mov	DWORD PTR [ebx+4], ecx
	jmp	SHORT $LN28@tmalloc_sm
$LN19@tmalloc_sm:
	cmp	edx, DWORD PTR [ebx+16]
	jb	$LN8@tmalloc_sm
	cmp	DWORD PTR [edx+16], esi
	jne	SHORT $LN24@tmalloc_sm
	mov	DWORD PTR [edx+16], eax
	jmp	SHORT $LN25@tmalloc_sm
$LN24@tmalloc_sm:
	mov	DWORD PTR [edx+20], eax
$LN25@tmalloc_sm:
	test	eax, eax
	je	SHORT $LN28@tmalloc_sm
$LN53@tmalloc_sm:
	cmp	eax, DWORD PTR [ebx+16]
	jb	$LN8@tmalloc_sm
	mov	DWORD PTR [eax+24], edx
	mov	ecx, DWORD PTR [esi+16]
	test	ecx, ecx
	je	SHORT $LN31@tmalloc_sm
	cmp	ecx, DWORD PTR [ebx+16]
	jb	$LN8@tmalloc_sm
	mov	DWORD PTR [eax+16], ecx
	mov	DWORD PTR [ecx+24], eax
$LN31@tmalloc_sm:
	mov	ecx, DWORD PTR [esi+20]
	test	ecx, ecx
	je	SHORT $LN28@tmalloc_sm
	cmp	ecx, DWORD PTR [ebx+16]
	jb	$LN8@tmalloc_sm
	mov	DWORD PTR [eax+20], ecx
	mov	DWORD PTR [ecx+24], eax
$LN28@tmalloc_sm:

; 3720 :       if (rsize < MIN_CHUNK_SIZE)

	cmp	edi, 16					; 00000010H
	jae	SHORT $LN35@tmalloc_sm

; 3721 :         set_inuse_and_pinuse(m, v, (rsize + nb));

	lea	eax, DWORD PTR [edi+ebp]
	or	eax, 3
	mov	DWORD PTR [esi+4], eax
	lea	eax, DWORD PTR [edi+esi]
	or	DWORD PTR [eax+ebp+4], 1

; 3726 :       }
; 3727 :       return chunk2mem(v);

	lea	eax, DWORD PTR [esi+8]
	pop	edi

; 3732 :   return 0;
; 3733 : }

	pop	esi
	pop	ebp
	pop	ebx
	add	esp, 16					; 00000010H
	ret	0
$LN35@tmalloc_sm:

; 3722 :       else {
; 3723 :         set_size_and_pinuse_of_inuse_chunk(m, v, nb);
; 3724 :         set_size_and_pinuse_of_free_chunk(r, rsize);

	mov	ecx, DWORD PTR _r$1$[esp+32]
	or	ebp, 3
	mov	eax, edi
	mov	DWORD PTR [esi+4], ebp
	or	eax, 1
	mov	DWORD PTR [ecx+4], eax
	mov	DWORD PTR [ecx+edi], edi

; 3725 :         replace_dv(m, r, rsize);

	mov	ecx, DWORD PTR [ebx+8]
	test	ecx, ecx
	je	SHORT $LN37@tmalloc_sm
	mov	edx, DWORD PTR [ebx+20]
	lea	eax, DWORD PTR [ebx+36]
	shr	ecx, 3
	lea	eax, DWORD PTR [eax+ecx*8]
	mov	ebp, eax
	mov	eax, DWORD PTR [ebx]
	mov	DWORD PTR tv650[esp+32], eax
	mov	eax, 1
	shl	eax, cl
	test	eax, DWORD PTR tv650[esp+32]
	jne	SHORT $LN38@tmalloc_sm
	mov	eax, DWORD PTR tv650[esp+32]
	bts	eax, ecx
	mov	DWORD PTR [ebx], eax
	mov	eax, ebp
	jmp	SHORT $LN41@tmalloc_sm
$LN38@tmalloc_sm:
	lea	eax, DWORD PTR [ebx+36]
	mov	ebp, DWORD PTR [eax+ecx*8+8]
	lea	eax, DWORD PTR [eax+ecx*8]
	cmp	ebp, DWORD PTR [ebx+16]
	jb	SHORT $LN8@tmalloc_sm
$LN41@tmalloc_sm:
	mov	DWORD PTR [eax+8], edx
	mov	DWORD PTR [ebp+12], edx
	mov	DWORD PTR [edx+8], ebp
	mov	DWORD PTR [edx+12], eax
$LN37@tmalloc_sm:
	mov	eax, DWORD PTR _r$1$[esp+32]
	mov	DWORD PTR [ebx+8], edi
	pop	edi
	mov	DWORD PTR [ebx+20], eax

; 3726 :       }
; 3727 :       return chunk2mem(v);

	lea	eax, DWORD PTR [esi+8]

; 3732 :   return 0;
; 3733 : }

	pop	esi
	pop	ebp
	pop	ebx
	add	esp, 16					; 00000010H
	ret	0
$LN8@tmalloc_sm:

; 3728 :     }
; 3729 :   }
; 3730 : 
; 3731 :   CORRUPTION_ERROR_ACTION(m);

	call	DWORD PTR __imp__abort
$LN64@tmalloc_sm:
	int	3
_tmalloc_small ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_i$1$ = -12						; size = 4
_r$1$ = -12						; size = 4
_p$1$ = -8						; size = 4
_mem$1$ = -4						; size = 4
_dlmalloc PROC
; _bytes$ = ecx

; 4026 : void* dlmalloc(size_t bytes) {

	sub	esp, 12					; 0000000cH
	push	ebx
	push	esi
	push	edi

; 4027 :   /*
; 4028 :      Basic algorithm:
; 4029 :      If a small request (< 256 bytes minus per-chunk overhead):
; 4030 :        1. If one exists, use a remainderless chunk in associated smallbin.
; 4031 :           (Remainderless means that there are too few excess bytes to
; 4032 :           represent as a chunk.)
; 4033 :        2. If it is big enough, use the dv chunk, which is normally the
; 4034 :           chunk adjacent to the one used for the most recent small request.
; 4035 :        3. If one exists, split the smallest available chunk in a bin,
; 4036 :           saving remainder in dv.
; 4037 :        4. If it is big enough, use the top chunk.
; 4038 :        5. If available, get memory from system and use it
; 4039 :      Otherwise, for a large request:
; 4040 :        1. Find the smallest available binned chunk that fits, and use it
; 4041 :           if it is better fitting than dv chunk, splitting if necessary.
; 4042 :        2. If better fitting than any binned chunk, use the dv chunk.
; 4043 :        3. If it is big enough, use the top chunk.
; 4044 :        4. If request size >= mmap threshold, try to directly mmap this chunk.
; 4045 :        5. If available, get memory from system and use it
; 4046 : 
; 4047 :      The ugly goto's here ensure that postaction occurs along all paths.
; 4048 :   */
; 4049 : 
; 4050 :   if (!PREACTION(gm)) {
; 4051 :     void* mem;
; 4052 :     size_t nb;
; 4053 :     if (bytes <= MAX_SMALL_REQUEST) {

	cmp	ecx, 244				; 000000f4H
	ja	$LN3@dlmalloc

; 4054 :       bindex_t idx;
; 4055 :       binmap_t smallbits;
; 4056 :       nb = (bytes < MIN_REQUEST)? MIN_CHUNK_SIZE : pad_request(bytes);

	cmp	ecx, 11					; 0000000bH
	jae	SHORT $LN35@dlmalloc
	mov	esi, 16					; 00000010H
	jmp	SHORT $LN36@dlmalloc
$LN35@dlmalloc:
	lea	esi, DWORD PTR [ecx+11]
	and	esi, -8					; fffffff8H
$LN36@dlmalloc:

; 4057 :       idx = small_index(nb);
; 4058 :       smallbits = gm->smallmap >> idx;

	mov	edi, DWORD PTR __gm_
	mov	ecx, esi
	shr	ecx, 3
	mov	eax, edi
	shr	eax, cl

; 4059 : 
; 4060 :       if ((smallbits & 0x3U) != 0) { /* Remainderless fit to a smallbin. */

	test	al, 3
	je	SHORT $LN5@dlmalloc

; 4061 :         mchunkptr b, p;
; 4062 :         idx += ~smallbits & 1;       /* Uses next bin if idx empty */

	not	eax
	and	eax, 1
	add	ecx, eax

; 4063 :         b = smallbin_at(gm, idx);
; 4064 :         p = b->fd;

	mov	ebx, DWORD PTR __gm_[ecx*8+44]
	lea	esi, DWORD PTR __gm_[ecx*8+36]

; 4065 :         assert(chunksize(p) == small_index2size(idx));
; 4066 :         unlink_first_small_chunk(gm, b, p, idx);

	mov	eax, DWORD PTR [ebx+8]
	lea	edx, DWORD PTR [ebx+8]
	cmp	esi, eax
	jne	SHORT $LN7@dlmalloc
	btr	edi, ecx
	mov	DWORD PTR __gm_, edi
	jmp	SHORT $LN10@dlmalloc
$LN7@dlmalloc:
	cmp	eax, DWORD PTR __gm_+16
	jb	$LN16@dlmalloc
	mov	DWORD PTR [esi+8], eax
	mov	DWORD PTR [eax+12], esi
$LN10@dlmalloc:

; 4067 :         set_inuse_and_pinuse(gm, p, small_index2size(idx));

	lea	eax, DWORD PTR [ecx*8]
	or	eax, 3
	pop	edi
	mov	DWORD PTR [ebx+4], eax

; 4149 : 
; 4150 :   postaction:
; 4151 :     POSTACTION(gm);
; 4152 :     return mem;

	mov	eax, edx
	or	DWORD PTR [ebx+ecx*8+4], 1

; 4153 :   }
; 4154 : 
; 4155 :   return 0;
; 4156 : }

	pop	esi
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN5@dlmalloc:

; 4068 :         mem = chunk2mem(p);
; 4069 :         check_malloced_chunk(gm, mem, nb);
; 4070 :         goto postaction;
; 4071 :       }
; 4072 : 
; 4073 :       else if (nb > gm->dvsize) {

	mov	edx, DWORD PTR __gm_+8
	cmp	esi, edx
	jbe	$LN118@dlmalloc

; 4074 :         if (smallbits != 0) { /* Use chunk in next nonempty smallbin */

	test	eax, eax
	je	$LN12@dlmalloc

; 4075 :           mchunkptr b, p, r;
; 4076 :           size_t rsize;
; 4077 :           bindex_t i;
; 4078 :           binmap_t leftbits = (smallbits << idx) & left_bits(idx2bit(idx));

	and	eax, -2					; fffffffeH
	shl	eax, cl

; 4079 :           binmap_t leastbit = least_bit(leftbits);

	mov	edx, eax
	neg	edx
	and	edx, eax

; 4080 :           compute_bit2idx(leastbit, i);

	dec	edx
	mov	eax, edx
	shr	eax, 12					; 0000000cH
	and	eax, 16					; 00000010H
	mov	ecx, eax
	shr	edx, cl
	mov	ecx, edx
	shr	ecx, 5
	and	ecx, 8
	shr	edx, cl
	add	eax, ecx
	mov	ecx, edx
	shr	ecx, 2
	and	ecx, 4
	shr	edx, cl
	add	eax, ecx
	mov	ecx, edx
	shr	ecx, 1
	and	ecx, 2
	shr	edx, cl
	add	eax, ecx
	mov	ecx, edx
	shr	ecx, 1
	and	ecx, 1
	shr	edx, cl
	add	edx, eax
	add	edx, ecx
	mov	DWORD PTR _i$1$[esp+24], edx

; 4081 :           b = smallbin_at(gm, i);

	lea	ebx, DWORD PTR [edx*8]

; 4082 :           p = b->fd;

	mov	eax, DWORD PTR __gm_[ebx+44]
	lea	ecx, DWORD PTR __gm_[ebx+36]
	mov	DWORD PTR _p$1$[esp+24], eax

; 4083 :           assert(chunksize(p) == small_index2size(i));
; 4084 :           unlink_first_small_chunk(gm, b, p, i);

	lea	edx, DWORD PTR [eax+8]
	mov	eax, DWORD PTR [edx]
	mov	DWORD PTR _mem$1$[esp+24], edx
	cmp	ecx, eax
	jne	SHORT $LN14@dlmalloc
	mov	eax, DWORD PTR _i$1$[esp+24]
	btr	edi, eax
	mov	DWORD PTR __gm_, edi
	jmp	SHORT $LN17@dlmalloc
$LN14@dlmalloc:
	cmp	eax, DWORD PTR __gm_+16
	jb	$LN16@dlmalloc
	mov	DWORD PTR [ecx+8], eax
	mov	DWORD PTR [eax+12], ecx
$LN17@dlmalloc:

; 4085 :           rsize = small_index2size(i) - nb;
; 4086 :           /* Fit here cannot be remainderless if 4byte sizes */
; 4087 :           if (SIZE_T_SIZE != 4 && rsize < MIN_CHUNK_SIZE)
; 4088 :             set_inuse_and_pinuse(gm, p, small_index2size(i));
; 4089 :           else {
; 4090 :             set_size_and_pinuse_of_inuse_chunk(gm, p, nb);

	mov	ecx, DWORD PTR _p$1$[esp+24]
	mov	eax, esi
	or	eax, 3
	sub	ebx, esi
	mov	DWORD PTR [ecx+4], eax

; 4091 :             r = chunk_plus_offset(p, nb);

	add	ecx, esi

; 4092 :             set_size_and_pinuse_of_free_chunk(r, rsize);

	mov	eax, ebx
	mov	DWORD PTR _r$1$[esp+24], ecx
	or	eax, 1
	mov	DWORD PTR [ecx+4], eax
	mov	DWORD PTR [ecx+ebx], ebx

; 4093 :             replace_dv(gm, r, rsize);

	mov	ecx, DWORD PTR __gm_+8
	test	ecx, ecx
	je	SHORT $LN20@dlmalloc
	mov	edi, DWORD PTR __gm_+20
	mov	edx, DWORD PTR _mem$1$[esp+24]
	shr	ecx, 3
	lea	eax, DWORD PTR __gm_[ecx*8+36]
	mov	esi, eax
	mov	eax, 1
	shl	eax, cl
	test	eax, DWORD PTR __gm_
	jne	SHORT $LN21@dlmalloc
	mov	eax, DWORD PTR __gm_
	bts	eax, ecx
	mov	DWORD PTR __gm_, eax
	mov	eax, esi
	jmp	SHORT $LN24@dlmalloc
$LN21@dlmalloc:
	mov	esi, DWORD PTR __gm_[ecx*8+44]
	lea	eax, DWORD PTR __gm_[ecx*8+36]
	cmp	esi, DWORD PTR __gm_+16
	jb	SHORT $LN16@dlmalloc
$LN24@dlmalloc:
	mov	DWORD PTR [eax+8], edi
	mov	DWORD PTR [esi+12], edi
	mov	DWORD PTR [edi+8], esi
	mov	DWORD PTR [edi+12], eax
$LN20@dlmalloc:
	mov	eax, DWORD PTR _r$1$[esp+24]
	pop	edi

; 4153 :   }
; 4154 : 
; 4155 :   return 0;
; 4156 : }

	pop	esi
	mov	DWORD PTR __gm_+8, ebx
	mov	DWORD PTR __gm_+20, eax
	mov	eax, edx
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN16@dlmalloc:

; 4083 :           assert(chunksize(p) == small_index2size(i));
; 4084 :           unlink_first_small_chunk(gm, b, p, i);

	call	DWORD PTR __imp__abort
$LN12@dlmalloc:

; 4094 :           }
; 4095 :           mem = chunk2mem(p);
; 4096 :           check_malloced_chunk(gm, mem, nb);
; 4097 :           goto postaction;
; 4098 :         }
; 4099 : 
; 4100 :         else if (gm->treemap != 0 && (mem = tmalloc_small(gm, nb)) != 0) {

	cmp	DWORD PTR __gm_+4, 0
	je	SHORT $LN28@dlmalloc
	mov	edx, esi
	mov	ecx, OFFSET __gm_
	call	_tmalloc_small

; 4101 :           check_malloced_chunk(gm, mem, nb);
; 4102 :           goto postaction;
; 4103 :         }
; 4104 :       }
; 4105 :     }

	jmp	SHORT $LN122@dlmalloc
$LN3@dlmalloc:

; 4106 :     else if (bytes >= MAX_REQUEST)

	cmp	ecx, -64				; ffffffc0H
	jb	SHORT $LN26@dlmalloc

; 4107 :       nb = MAX_SIZE_T; /* Too big to allocate. Force failure (in sys alloc) */

	or	esi, -1
	jmp	SHORT $LN119@dlmalloc
$LN26@dlmalloc:

; 4108 :     else {
; 4109 :       nb = pad_request(bytes);

	lea	esi, DWORD PTR [ecx+11]
	and	esi, -8					; fffffff8H

; 4110 :       if (gm->treemap != 0 && (mem = tmalloc_large(gm, nb)) != 0) {

	cmp	DWORD PTR __gm_+4, 0
	je	SHORT $LN119@dlmalloc
	mov	edx, esi
	mov	ecx, OFFSET __gm_
	call	_tmalloc_large
$LN122@dlmalloc:

; 4111 :         check_malloced_chunk(gm, mem, nb);
; 4112 :         goto postaction;
; 4113 :       }
; 4114 :     }
; 4115 : 
; 4116 :     if (nb <= gm->dvsize) {

	mov	edx, eax
	test	edx, edx
	jne	$postaction$124
$LN119@dlmalloc:
	mov	edx, DWORD PTR __gm_+8
$LN28@dlmalloc:
	cmp	esi, edx
	ja	SHORT $LN29@dlmalloc
$LN118@dlmalloc:

; 4117 :       size_t rsize = gm->dvsize - nb;
; 4118 :       mchunkptr p = gm->dv;

	mov	ebx, DWORD PTR __gm_+20
	mov	edi, edx
	sub	edi, esi

; 4119 :       if (rsize >= MIN_CHUNK_SIZE) { /* split dv */

	cmp	edi, 16					; 00000010H
	jb	SHORT $LN31@dlmalloc

; 4120 :         mchunkptr r = gm->dv = chunk_plus_offset(p, nb);

	lea	ecx, DWORD PTR [ebx+esi]

; 4121 :         gm->dvsize = rsize;

	mov	DWORD PTR __gm_+8, edi

; 4122 :         set_size_and_pinuse_of_free_chunk(r, rsize);

	mov	eax, edi
	mov	DWORD PTR __gm_+20, ecx
	or	eax, 1

; 4130 :       }
; 4131 :       mem = chunk2mem(p);

	lea	edx, DWORD PTR [ebx+8]
	mov	DWORD PTR [ecx+4], eax
	or	esi, 3
	mov	DWORD PTR [ecx+edi], edi

; 4149 : 
; 4150 :   postaction:
; 4151 :     POSTACTION(gm);
; 4152 :     return mem;

	mov	eax, edx
	pop	edi
	mov	DWORD PTR [ebx+4], esi

; 4153 :   }
; 4154 : 
; 4155 :   return 0;
; 4156 : }

	pop	esi
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN31@dlmalloc:

; 4123 :         set_size_and_pinuse_of_inuse_chunk(gm, p, nb);
; 4124 :       }
; 4125 :       else { /* exhaust dv */
; 4126 :         size_t dvs = gm->dvsize;
; 4127 :         gm->dvsize = 0;
; 4128 :         gm->dv = 0;
; 4129 :         set_inuse_and_pinuse(gm, p, dvs);

	mov	eax, edx
	mov	DWORD PTR __gm_+8, 0
	or	eax, 3
	mov	DWORD PTR __gm_+20, 0
	mov	DWORD PTR [ebx+4], eax
	or	DWORD PTR [edx+ebx+4], 1

; 4130 :       }
; 4131 :       mem = chunk2mem(p);

	lea	edx, DWORD PTR [ebx+8]
	pop	edi

; 4153 :   }
; 4154 : 
; 4155 :   return 0;
; 4156 : }

	pop	esi
	mov	eax, edx
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN29@dlmalloc:

; 4132 :       check_malloced_chunk(gm, mem, nb);
; 4133 :       goto postaction;
; 4134 :     }
; 4135 : 
; 4136 :     else if (nb < gm->topsize) { /* Split top */

	mov	edx, DWORD PTR __gm_+12
	cmp	esi, edx
	jae	SHORT $LN33@dlmalloc

; 4137 :       size_t rsize = gm->topsize -= nb;
; 4138 :       mchunkptr p = gm->top;

	mov	eax, DWORD PTR __gm_+24
	sub	edx, esi
	mov	ecx, eax
	mov	DWORD PTR __gm_+12, edx

; 4139 :       mchunkptr r = gm->top = chunk_plus_offset(p, nb);

	add	eax, esi
	or	edx, 1
	mov	DWORD PTR __gm_+24, eax

; 4140 :       r->head = rsize | PINUSE_BIT;
; 4141 :       set_size_and_pinuse_of_inuse_chunk(gm, p, nb);

	or	esi, 3
	pop	edi
	mov	DWORD PTR [eax+4], edx

; 4142 :       mem = chunk2mem(p);

	lea	edx, DWORD PTR [ecx+8]
	mov	DWORD PTR [ecx+4], esi

; 4149 : 
; 4150 :   postaction:
; 4151 :     POSTACTION(gm);
; 4152 :     return mem;

	mov	eax, edx

; 4153 :   }
; 4154 : 
; 4155 :   return 0;
; 4156 : }

	pop	esi
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN33@dlmalloc:

; 4143 :       check_top_chunk(gm, gm->top);
; 4144 :       check_malloced_chunk(gm, mem, nb);
; 4145 :       goto postaction;
; 4146 :     }
; 4147 : 
; 4148 :     mem = sys_alloc(gm, nb);

	mov	edx, esi
	mov	ecx, OFFSET __gm_
	call	_sys_alloc
	mov	edx, eax
$postaction$124:

; 4153 :   }
; 4154 : 
; 4155 :   return 0;
; 4156 : }

	pop	edi
	pop	esi
	mov	eax, edx
	pop	ebx
	add	esp, 12					; 0000000cH
	ret	0
$LN120@dlmalloc:
_dlmalloc ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_RP$1$ = -12						; size = 4
_RP$1$ = -12						; size = 4
tv1575 = -12						; size = 4
_F$1$ = -8						; size = 4
_next$1$ = -8						; size = 4
_XP$1$ = -4						; size = 4
_F$1$ = -4						; size = 4
tv1480 = -4						; size = 4
tv1461 = -4						; size = 4
_F$1$ = -4						; size = 4
_XP$1$ = -4						; size = 4
_F$1$ = -4						; size = 4
_dlfree	PROC
; _mem$ = ecx

; 4158 : void dlfree(void* mem) {

	sub	esp, 12					; 0000000cH

; 4159 :   /*
; 4160 :      Consolidate freed chunks with preceeding or succeeding bordering
; 4161 :      free chunks, if they exist, and then place in a bin.  Intermixed
; 4162 :      with special cases for top, dv, mmapped chunks, and usage errors.
; 4163 :   */
; 4164 : 
; 4165 :   if (mem != 0) {

	test	ecx, ecx
	je	SHORT $postaction$173

; 4166 :     mchunkptr p  = mem2chunk(mem);

	push	ebx
	push	esi
	lea	esi, DWORD PTR [ecx-8]

; 4167 : #if FOOTERS
; 4168 :     mstate fm = get_mstate_for(p);
; 4169 :     if (!ok_magic(fm)) {
; 4170 :       USAGE_ERROR_ACTION(fm, p);
; 4171 :       return;
; 4172 :     }
; 4173 : #else /* FOOTERS */
; 4174 : #define fm gm
; 4175 : #endif /* FOOTERS */
; 4176 :     if (!PREACTION(fm)) {
; 4177 :       check_inuse_chunk(fm, p);
; 4178 :       if (RTCHECK(ok_address(fm, p) && ok_cinuse(p))) {

	mov	ecx, DWORD PTR __gm_+16
	push	edi
	cmp	esi, ecx
	jb	$erroraction$174
	mov	eax, DWORD PTR [esi+4]
	test	al, 2
	je	$erroraction$174

; 4179 :         size_t psize = chunksize(p);

	mov	edi, eax
	and	edi, -4					; fffffffcH

; 4180 :         mchunkptr next = chunk_plus_offset(p, psize);

	lea	edx, DWORD PTR [edi+esi]
	mov	DWORD PTR _next$1$[esp+24], edx

; 4181 :         if (!pinuse(p)) {

	test	al, 1
	jne	$LN160@dlfree

; 4182 :           size_t prevsize = p->prev_foot;

	mov	ebx, DWORD PTR [esi]

; 4183 :           if ((prevsize & IS_MMAPPED_BIT) != 0) {

	test	bl, 1
	je	SHORT $LN13@dlfree

; 4184 :             prevsize &= ~IS_MMAPPED_BIT;

	and	ebx, -2					; fffffffeH

; 4185 :             psize += prevsize + MMAP_FOOT_PAD;

	add	edi, 16					; 00000010H
	add	edi, ebx

; 4186 :             if (CALL_MUNMAP((char*)p - prevsize, psize) == 0)

	sub	esi, ebx
	mov	edx, edi
	mov	ecx, esi
	call	_win32munmap
	test	eax, eax
	jne	SHORT $LN166@dlfree

; 4187 :               fm->footprint -= psize;

	sub	DWORD PTR __gm_+428, edi
$LN166@dlfree:
	pop	edi
	pop	esi
	pop	ebx
$postaction$173:

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH
	ret	0
$LN13@dlfree:

; 4188 :             goto postaction;
; 4189 :           }
; 4190 :           else {
; 4191 :             mchunkptr prev = chunk_minus_offset(p, prevsize);

	sub	esi, ebx

; 4192 :             psize += prevsize;

	add	edi, ebx

; 4193 :             p = prev;
; 4194 :             if (RTCHECK(ok_address(fm, prev))) { /* consolidate backward */

	cmp	esi, ecx
	jb	$erroraction$174

; 4195 :               if (p != fm->dv) {

	cmp	esi, DWORD PTR __gm_+20
	je	$LN18@dlfree

; 4196 :                 unlink_chunk(fm, p, prevsize);

	shr	ebx, 3
	cmp	ebx, 32					; 00000020H
	jae	$LN20@dlfree
	mov	eax, DWORD PTR [esi+8]
	mov	DWORD PTR _F$1$[esp+24], eax
	mov	eax, DWORD PTR [esi+12]
	cmp	DWORD PTR _F$1$[esp+24], eax
	jne	SHORT $LN22@dlfree
	mov	eax, DWORD PTR __gm_
	btr	eax, ebx
	mov	DWORD PTR __gm_, eax
	jmp	SHORT $LN160@dlfree
$LN22@dlfree:
	lea	ebx, DWORD PTR __gm_[ebx*8+36]
	mov	DWORD PTR tv1575[esp+24], ebx
	mov	ebx, DWORD PTR _F$1$[esp+24]
	cmp	ebx, DWORD PTR tv1575[esp+24]
	je	SHORT $LN26@dlfree
	cmp	ebx, ecx
	jb	$erroraction$174
$LN26@dlfree:
	cmp	eax, DWORD PTR tv1575[esp+24]
	je	SHORT $LN27@dlfree
	cmp	eax, ecx
	jb	$erroraction$174
$LN27@dlfree:
	mov	DWORD PTR [ebx+12], eax
	mov	DWORD PTR [eax+8], ebx
$LN159@dlfree:

; 4201 :                 goto postaction;
; 4202 :               }
; 4203 :             }
; 4204 :             else
; 4205 :               goto erroraction;
; 4206 :           }
; 4207 :         }
; 4208 : 
; 4209 :         if (RTCHECK(ok_next(p, next) && ok_pinuse(next))) {

	mov	ecx, DWORD PTR __gm_+16
$LN160@dlfree:
	cmp	esi, edx
	jae	$erroraction$174
	mov	ebx, DWORD PTR [edx+4]
	test	bl, 1
	je	$erroraction$174

; 4210 :           if (!cinuse(next)) {  /* consolidate forward */

	test	bl, 2
	jne	$LN56@dlfree

; 4211 :             if (next == fm->top) {

	cmp	edx, DWORD PTR __gm_+24
	jne	$LN58@dlfree

; 4212 :               size_t tsize = fm->topsize += psize;

	mov	ecx, DWORD PTR __gm_+12
	add	ecx, edi

; 4213 :               fm->top = p;

	mov	DWORD PTR __gm_+24, esi

; 4214 :               p->head = tsize | PINUSE_BIT;

	mov	eax, ecx
	mov	DWORD PTR __gm_+12, ecx
	or	eax, 1
	mov	DWORD PTR [esi+4], eax

; 4215 :               if (p == fm->dv) {

	cmp	esi, DWORD PTR __gm_+20
	jne	SHORT $LN60@dlfree

; 4216 :                 fm->dv = 0;

	mov	DWORD PTR __gm_+20, 0

; 4217 :                 fm->dvsize = 0;

	mov	DWORD PTR __gm_+8, 0
$LN60@dlfree:

; 4218 :               }
; 4219 :               if (should_trim(fm, tsize))

	cmp	ecx, DWORD PTR __gm_+28
	jbe	$LN166@dlfree

; 4220 :                 sys_trim(fm, 0);

	pop	edi
	pop	esi
	mov	ecx, OFFSET __gm_
	pop	ebx

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH

; 4220 :                 sys_trim(fm, 0);

	jmp	_sys_trim
$LN20@dlfree:

; 4196 :                 unlink_chunk(fm, p, prevsize);

	mov	eax, DWORD PTR [esi+12]
	mov	ebx, DWORD PTR [esi+24]
	mov	DWORD PTR _XP$1$[esp+24], ebx
	cmp	eax, esi
	je	SHORT $LN28@dlfree
	mov	edx, DWORD PTR [esi+8]
	cmp	edx, ecx
	mov	DWORD PTR _F$1$[esp+24], edx
	mov	edx, DWORD PTR _next$1$[esp+24]
	jb	$erroraction$174
	mov	ecx, DWORD PTR _F$1$[esp+24]
	mov	DWORD PTR [ecx+12], eax
	mov	DWORD PTR [eax+8], ecx
	mov	ecx, DWORD PTR __gm_+16
	jmp	SHORT $LN36@dlfree
$LN28@dlfree:
	mov	eax, DWORD PTR [esi+20]
	lea	ebx, DWORD PTR [esi+20]
	mov	DWORD PTR _RP$1$[esp+24], ebx
	test	eax, eax
	jne	SHORT $LN161@dlfree
	mov	eax, DWORD PTR [esi+16]
	lea	ebx, DWORD PTR [esi+16]
	mov	DWORD PTR _RP$1$[esp+24], ebx
	test	eax, eax
	je	SHORT $LN165@dlfree
$LN161@dlfree:
	mov	edx, DWORD PTR _RP$1$[esp+24]
	npad	1
$LL2@dlfree:
	cmp	DWORD PTR [eax+20], 0
	lea	ebx, DWORD PTR [eax+20]
	jne	SHORT $LN34@dlfree
	cmp	DWORD PTR [eax+16], 0
	lea	ebx, DWORD PTR [eax+16]
	je	SHORT $LN3@dlfree
$LN34@dlfree:
	mov	eax, DWORD PTR [ebx]
	mov	edx, ebx
	jmp	SHORT $LL2@dlfree
$LN3@dlfree:
	cmp	edx, DWORD PTR __gm_+16
	mov	DWORD PTR _RP$1$[esp+24], edx
	mov	edx, DWORD PTR _next$1$[esp+24]
	jb	$erroraction$174
	mov	ebx, DWORD PTR _RP$1$[esp+24]
	mov	DWORD PTR [ebx], 0
	mov	ecx, DWORD PTR __gm_+16
$LN165@dlfree:
	mov	ebx, DWORD PTR _XP$1$[esp+24]
$LN36@dlfree:
	test	ebx, ebx
	je	$LN160@dlfree
	mov	edx, DWORD PTR [esi+28]
	cmp	esi, DWORD PTR __gm_[edx*4+300]
	mov	edx, DWORD PTR _next$1$[esp+24]
	jne	SHORT $LN38@dlfree
	mov	ecx, DWORD PTR [esi+28]
	mov	DWORD PTR __gm_[ecx*4+300], eax
	test	eax, eax
	jne	SHORT $LN138@dlfree
	mov	ecx, DWORD PTR __gm_+4
	mov	eax, DWORD PTR [esi+28]
	btr	ecx, eax
	mov	DWORD PTR __gm_+4, ecx
	jmp	$LN159@dlfree
$LN38@dlfree:
	cmp	ebx, ecx
	jb	$erroraction$174
	cmp	DWORD PTR [ebx+16], esi
	jne	SHORT $LN43@dlfree
	mov	DWORD PTR [ebx+16], eax
	jmp	SHORT $LN44@dlfree
$LN43@dlfree:
	mov	DWORD PTR [ebx+20], eax
$LN44@dlfree:
	test	eax, eax
	je	$LN159@dlfree
$LN138@dlfree:
	cmp	eax, DWORD PTR __gm_+16
	jb	$erroraction$174
	mov	DWORD PTR [eax+24], ebx
	mov	ecx, DWORD PTR [esi+16]
	test	ecx, ecx
	je	SHORT $LN50@dlfree
	cmp	ecx, DWORD PTR __gm_+16
	jb	$erroraction$174
	mov	DWORD PTR [eax+16], ecx
	mov	DWORD PTR [ecx+24], eax
$LN50@dlfree:
	mov	ecx, DWORD PTR [esi+20]
	test	ecx, ecx
	je	$LN159@dlfree
	cmp	ecx, DWORD PTR __gm_+16
	jb	$erroraction$174
	mov	DWORD PTR [eax+20], ecx
	mov	DWORD PTR [ecx+24], eax

; 4201 :                 goto postaction;
; 4202 :               }
; 4203 :             }
; 4204 :             else
; 4205 :               goto erroraction;
; 4206 :           }
; 4207 :         }
; 4208 : 
; 4209 :         if (RTCHECK(ok_next(p, next) && ok_pinuse(next))) {

	jmp	$LN159@dlfree
$LN18@dlfree:

; 4197 :               }
; 4198 :               else if ((next->head & INUSE_BITS) == INUSE_BITS) {

	mov	eax, DWORD PTR [edx+4]
	and	eax, 3
	cmp	al, 3
	jne	$LN160@dlfree

; 4199 :                 fm->dvsize = psize;

	mov	DWORD PTR __gm_+8, edi

; 4200 :                 set_free_with_pinuse(p, psize, next);

	mov	eax, edi
	and	DWORD PTR [edx+4], -2			; fffffffeH
	or	eax, 1
	mov	DWORD PTR [esi+4], eax
	mov	DWORD PTR [esi+edi], edi
	pop	edi
	pop	esi
	pop	ebx

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH
	ret	0
$LN58@dlfree:

; 4221 :               goto postaction;
; 4222 :             }
; 4223 :             else if (next == fm->dv) {

	cmp	edx, DWORD PTR __gm_+20
	jne	SHORT $LN62@dlfree

; 4224 :               size_t dsize = fm->dvsize += psize;

	mov	ecx, DWORD PTR __gm_+8
	add	ecx, edi

; 4225 :               fm->dv = p;

	mov	DWORD PTR __gm_+20, esi

; 4226 :               set_size_and_pinuse_of_free_chunk(p, dsize);

	mov	eax, ecx
	mov	DWORD PTR __gm_+8, ecx
	or	eax, 1
	mov	DWORD PTR [esi+4], eax
	pop	edi
	mov	DWORD PTR [ecx+esi], ecx
	pop	esi
	pop	ebx

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH
	ret	0
$LN62@dlfree:

; 4227 :               goto postaction;
; 4228 :             }
; 4229 :             else {
; 4230 :               size_t nsize = chunksize(next);

	and	ebx, -4					; fffffffcH

; 4231 :               psize += nsize;

	add	edi, ebx

; 4232 :               unlink_chunk(fm, next, nsize);

	shr	ebx, 3
	cmp	ebx, 32					; 00000020H
	jae	SHORT $LN64@dlfree
	mov	eax, DWORD PTR [edx+8]
	mov	DWORD PTR _F$1$[esp+24], eax
	mov	eax, DWORD PTR [edx+12]
	mov	edx, DWORD PTR _F$1$[esp+24]
	cmp	edx, eax
	jne	SHORT $LN66@dlfree
	mov	eax, DWORD PTR __gm_
	btr	eax, ebx
	mov	DWORD PTR __gm_, eax
	jmp	$LN91@dlfree
$LN66@dlfree:
	lea	ebx, DWORD PTR __gm_[ebx*8+36]
	cmp	edx, ebx
	je	SHORT $LN70@dlfree
	cmp	edx, ecx
	jb	$erroraction$174
$LN70@dlfree:
	cmp	eax, ebx
	je	SHORT $LN71@dlfree
	cmp	eax, ecx
	jb	$erroraction$174
$LN71@dlfree:
	mov	DWORD PTR [edx+12], eax
	mov	DWORD PTR [eax+8], edx
	jmp	$LN91@dlfree
$LN64@dlfree:
	mov	eax, DWORD PTR [edx+12]
	mov	ebx, DWORD PTR [edx+24]
	mov	DWORD PTR _XP$1$[esp+24], ebx
	cmp	eax, edx
	je	SHORT $LN72@dlfree
	mov	ebx, DWORD PTR [edx+8]
	cmp	ebx, ecx
	mov	DWORD PTR _F$1$[esp+24], ebx
	mov	ebx, DWORD PTR _XP$1$[esp+24]
	jb	$erroraction$174
	mov	ecx, DWORD PTR _F$1$[esp+24]
	mov	DWORD PTR [ecx+12], eax
	mov	DWORD PTR [eax+8], ecx
	jmp	SHORT $LN80@dlfree
$LN72@dlfree:
	mov	eax, DWORD PTR [edx+20]
	lea	ebx, DWORD PTR [edx+20]
	mov	DWORD PTR _RP$1$[esp+24], ebx
	test	eax, eax
	jne	SHORT $LN162@dlfree
	mov	eax, DWORD PTR [edx+16]
	lea	ebx, DWORD PTR [edx+16]
	mov	DWORD PTR _RP$1$[esp+24], ebx
	test	eax, eax
	je	SHORT $LN164@dlfree
$LN162@dlfree:
	mov	edx, DWORD PTR _RP$1$[esp+24]
$LL4@dlfree:
	cmp	DWORD PTR [eax+20], 0
	lea	ebx, DWORD PTR [eax+20]
	jne	SHORT $LN78@dlfree
	cmp	DWORD PTR [eax+16], 0
	lea	ebx, DWORD PTR [eax+16]
	je	SHORT $LN5@dlfree
$LN78@dlfree:
	mov	eax, DWORD PTR [ebx]
	mov	edx, ebx
	jmp	SHORT $LL4@dlfree
$LN5@dlfree:
	cmp	edx, DWORD PTR __gm_+16
	mov	DWORD PTR _RP$1$[esp+24], edx
	mov	edx, DWORD PTR _next$1$[esp+24]
	jb	$erroraction$174
	mov	ebx, DWORD PTR _RP$1$[esp+24]
	mov	DWORD PTR [ebx], 0
$LN164@dlfree:
	mov	ebx, DWORD PTR _XP$1$[esp+24]
$LN80@dlfree:
	test	ebx, ebx
	je	$LN91@dlfree
	mov	ecx, DWORD PTR [edx+28]
	cmp	edx, DWORD PTR __gm_[ecx*4+300]
	mov	ecx, DWORD PTR __gm_+16
	jne	SHORT $LN82@dlfree
	mov	ecx, DWORD PTR [edx+28]
	mov	DWORD PTR __gm_[ecx*4+300], eax
	test	eax, eax
	jne	SHORT $LN137@dlfree
	mov	ecx, DWORD PTR __gm_+4
	mov	eax, DWORD PTR [edx+28]
	btr	ecx, eax
	mov	DWORD PTR __gm_+4, ecx
	jmp	SHORT $LN91@dlfree
$LN82@dlfree:
	cmp	ebx, ecx
	jb	$erroraction$174
	cmp	DWORD PTR [ebx+16], edx
	jne	SHORT $LN87@dlfree
	mov	DWORD PTR [ebx+16], eax
	jmp	SHORT $LN88@dlfree
$LN87@dlfree:
	mov	DWORD PTR [ebx+20], eax
$LN88@dlfree:
	test	eax, eax
	je	SHORT $LN91@dlfree
$LN137@dlfree:
	cmp	eax, DWORD PTR __gm_+16
	jb	$erroraction$174
	mov	DWORD PTR [eax+24], ebx
	mov	ecx, DWORD PTR [edx+16]
	test	ecx, ecx
	je	SHORT $LN94@dlfree
	cmp	ecx, DWORD PTR __gm_+16
	jb	$erroraction$174
	mov	DWORD PTR [eax+16], ecx
	mov	DWORD PTR [ecx+24], eax
$LN94@dlfree:
	mov	ecx, DWORD PTR [edx+20]
	test	ecx, ecx
	je	SHORT $LN91@dlfree
	cmp	ecx, DWORD PTR __gm_+16
	jb	$erroraction$174
	mov	DWORD PTR [eax+20], ecx
	mov	DWORD PTR [ecx+24], eax
$LN91@dlfree:

; 4233 :               set_size_and_pinuse_of_free_chunk(p, psize);

	mov	eax, edi
	or	eax, 1
	mov	DWORD PTR [esi+4], eax
	mov	DWORD PTR [edi+esi], edi

; 4234 :               if (p == fm->dv) {

	cmp	esi, DWORD PTR __gm_+20
	jne	SHORT $LN57@dlfree

; 4235 :                 fm->dvsize = psize;

	mov	DWORD PTR __gm_+8, edi
	pop	edi
	pop	esi
	pop	ebx

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH
	ret	0
$LN56@dlfree:

; 4236 :                 goto postaction;
; 4237 :               }
; 4238 :             }
; 4239 :           }
; 4240 :           else
; 4241 :             set_free_with_pinuse(p, psize, next);

	and	ebx, -2					; fffffffeH
	mov	eax, edi
	mov	DWORD PTR [edx+4], ebx
	or	eax, 1
	mov	DWORD PTR [esi+4], eax
	mov	DWORD PTR [edi+esi], edi
$LN57@dlfree:

; 4242 :           insert_chunk(fm, p, psize);

	mov	ecx, edi
	shr	ecx, 3
	cmp	ecx, 32					; 00000020H
	jae	SHORT $LN99@dlfree
	mov	ebx, DWORD PTR __gm_
	lea	edx, DWORD PTR __gm_[ecx*8+36]
	mov	eax, 1
	mov	edi, edx
	shl	eax, cl
	test	eax, ebx
	jne	SHORT $LN101@dlfree
	bts	ebx, ecx
	mov	DWORD PTR __gm_, ebx
	mov	DWORD PTR [edx+8], esi
	mov	DWORD PTR [edi+12], esi

; 4243 :           check_free_chunk(fm, p);
; 4244 :           goto postaction;

	mov	DWORD PTR [esi+12], edx
	mov	DWORD PTR [esi+8], edi
	pop	edi
	pop	esi
	pop	ebx

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH
	ret	0
$LN101@dlfree:

; 4242 :           insert_chunk(fm, p, psize);

	mov	edi, DWORD PTR [edx+8]
	cmp	edi, DWORD PTR __gm_+16
	jb	$erroraction$174
	mov	DWORD PTR [edx+8], esi
	mov	DWORD PTR [edi+12], esi

; 4243 :           check_free_chunk(fm, p);
; 4244 :           goto postaction;

	mov	DWORD PTR [esi+12], edx
	mov	DWORD PTR [esi+8], edi
	pop	edi
	pop	esi
	pop	ebx

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH
	ret	0
$LN99@dlfree:

; 4242 :           insert_chunk(fm, p, psize);

	mov	edx, edi
	shr	edx, 8
	test	edx, edx
	jne	SHORT $LN105@dlfree
	xor	ecx, ecx
	jmp	SHORT $LN108@dlfree
$LN105@dlfree:
	cmp	edx, 65535				; 0000ffffH
	jbe	SHORT $LN107@dlfree
	mov	ecx, 31					; 0000001fH
	jmp	SHORT $LN108@dlfree
$LN107@dlfree:
	lea	eax, DWORD PTR [edx-256]
	shr	eax, 16					; 00000010H
	and	eax, 8
	mov	ecx, eax
	shl	edx, cl
	lea	ecx, DWORD PTR [edx-4096]
	shr	ecx, 16					; 00000010H
	and	ecx, 4
	shl	edx, cl
	add	eax, ecx
	lea	ecx, DWORD PTR [edx-16384]
	shr	ecx, 16					; 00000010H
	and	ecx, 2
	shl	edx, cl
	shr	edx, 15					; 0000000fH
	sub	edx, ecx
	sub	edx, eax
	mov	eax, edi
	lea	ecx, DWORD PTR [edx+21]
	shr	eax, cl
	lea	ecx, DWORD PTR [edx+14]
	and	eax, 1
	lea	ecx, DWORD PTR [eax+ecx*2]
$LN108@dlfree:
	mov	eax, 1
	mov	DWORD PTR [esi+28], ecx
	mov	DWORD PTR [esi+20], 0
	lea	ebx, DWORD PTR __gm_[ecx*4+300]
	mov	DWORD PTR [esi+16], 0
	mov	edx, DWORD PTR __gm_+4
	shl	eax, cl
	test	eax, edx
	jne	SHORT $LN109@dlfree
	bts	edx, ecx
	mov	edi, esi
	mov	DWORD PTR __gm_+4, edx
	mov	edx, esi
	mov	DWORD PTR [ebx], esi
	mov	DWORD PTR [esi+24], ebx

; 4243 :           check_free_chunk(fm, p);
; 4244 :           goto postaction;

	mov	DWORD PTR [esi+12], edx
	mov	DWORD PTR [esi+8], edi
	pop	edi
	pop	esi
	pop	ebx

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH
	ret	0
$LN109@dlfree:

; 4242 :           insert_chunk(fm, p, psize);

	mov	edx, DWORD PTR [ebx]
	cmp	ecx, 31					; 0000001fH
	jne	SHORT $LN120@dlfree
	xor	eax, eax
	jmp	SHORT $LN121@dlfree
$LN120@dlfree:
	shr	ecx, 1
	mov	eax, 25					; 00000019H
	sub	eax, ecx
$LN121@dlfree:
	mov	ecx, eax
	mov	ebx, edi
	mov	eax, DWORD PTR [edx+4]
	and	eax, -4					; fffffffcH
	shl	ebx, cl
	cmp	eax, edi
	je	SHORT $LN111@dlfree
$LL6@dlfree:
	mov	eax, ebx
	add	ebx, ebx
	shr	eax, 31					; 0000001fH
	add	eax, 4
	lea	ecx, DWORD PTR [edx+eax*4]
	mov	eax, DWORD PTR [ecx]
	test	eax, eax
	je	SHORT $LN113@dlfree
	mov	edx, eax
	mov	eax, DWORD PTR [edx+4]
	and	eax, -4					; fffffffcH
	cmp	eax, edi
	jne	SHORT $LL6@dlfree
$LN111@dlfree:
	mov	eax, DWORD PTR __gm_+16
	mov	edi, DWORD PTR [edx+8]
	cmp	edx, eax
	jb	SHORT $erroraction$174
	cmp	edi, eax
	jb	SHORT $erroraction$174
	mov	DWORD PTR [edi+12], esi
	mov	DWORD PTR [edx+8], esi
	mov	DWORD PTR [esi+24], 0

; 4243 :           check_free_chunk(fm, p);
; 4244 :           goto postaction;

	mov	DWORD PTR [esi+12], edx
	mov	DWORD PTR [esi+8], edi
	pop	edi
	pop	esi
	pop	ebx

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH
	ret	0
$LN113@dlfree:

; 4242 :           insert_chunk(fm, p, psize);

	cmp	ecx, DWORD PTR __gm_+16
	jb	SHORT $erroraction$174
	mov	DWORD PTR [ecx], esi
	mov	edi, esi
	mov	DWORD PTR [esi+24], edx
	mov	edx, esi

; 4243 :           check_free_chunk(fm, p);
; 4244 :           goto postaction;

	mov	DWORD PTR [esi+12], edx
	mov	DWORD PTR [esi+8], edi
	pop	edi
	pop	esi
	pop	ebx

; 4249 :     postaction:
; 4250 :       POSTACTION(fm);
; 4251 :     }
; 4252 :   }
; 4253 : #if !FOOTERS
; 4254 : #undef fm
; 4255 : #endif /* FOOTERS */
; 4256 : }

	add	esp, 12					; 0000000cH
	ret	0
$erroraction$174:

; 4245 :         }
; 4246 :       }
; 4247 :     erroraction:
; 4248 :       USAGE_ERROR_ACTION(fm, p);

	call	DWORD PTR __imp__abort
$LN172@dlfree:
$LN170@dlfree:
	int	3
_dlfree	ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File I:\Vitalya\mine\NSProjectX\layers\xrRender\doug_lea_memory_allocator.c
_TEXT	SEGMENT
_nfree$1$ = -56						; size = 4
_mfree$1$ = -52						; size = 4
_sum$1$ = -48						; size = 4
_s$1$ = -44						; size = 4
$T1 = -40						; size = 40
$T2 = 8							; size = 4
_dlmallinfo PROC

; 4343 : struct mallinfo dlmallinfo(void) {

	push	ebp
	mov	ebp, esp
	and	esp, -8					; fffffff8H
	sub	esp, 60					; 0000003cH

; 2792 :     if (is_initialized(m)) {

	mov	edx, DWORD PTR __gm_+24
	mov	DWORD PTR $T1[esp+60], 0
	mov	DWORD PTR $T1[esp+64], 0
	mov	DWORD PTR $T1[esp+68], 0
	mov	DWORD PTR $T1[esp+72], 0
	mov	DWORD PTR $T1[esp+76], 0
	mov	DWORD PTR $T1[esp+80], 0
	mov	DWORD PTR $T1[esp+84], 0
	mov	DWORD PTR $T1[esp+88], 0
	mov	DWORD PTR $T1[esp+92], 0
	mov	DWORD PTR $T1[esp+96], 0

; 4343 : struct mallinfo dlmallinfo(void) {

	push	ebx
	push	esi
	push	edi

; 2792 :     if (is_initialized(m)) {

	test	edx, edx
	je	$LN9@dlmallinfo

; 2793 :       size_t nfree = SIZE_T_ONE; /* top always free */
; 2794 :       size_t mfree = m->topsize + TOP_FOOT_SIZE;

	mov	esi, DWORD PTR __gm_+12

; 2795 :       size_t sum = mfree;
; 2796 :       msegmentptr s = &m->seg;

	mov	ebx, OFFSET __gm_+440
	add	esi, 40					; 00000028H
	mov	DWORD PTR _nfree$1$[esp+72], 1
	mov	DWORD PTR _mfree$1$[esp+72], esi
	mov	DWORD PTR _sum$1$[esp+72], esi
	mov	DWORD PTR _s$1$[esp+72], ebx
	npad	4
$LL4@dlmallinfo:

; 2797 :       while (s != 0) {
; 2798 :         mchunkptr q = align_as_chunk(s->base);

	mov	edi, DWORD PTR [ebx]
	mov	eax, edi
	and	eax, 7
	je	SHORT $LN15@dlmallinfo
$LN14@dlmallinfo:
	neg	eax
	and	eax, 7
$LN15@dlmallinfo:
	add	eax, edi

; 2799 :         while (segment_holds(s, q) &&
; 2800 :                q != m->top && q->head != FENCEPOST_HEAD) {

	cmp	eax, edi
	jb	SHORT $LN7@dlmallinfo
	mov	ebx, DWORD PTR [ebx+4]
	add	ebx, edi
	npad	7
$LL6@dlmallinfo:
	cmp	eax, ebx
	jae	SHORT $LN24@dlmallinfo
	cmp	eax, edx
	je	SHORT $LN24@dlmallinfo
	mov	ecx, DWORD PTR [eax+4]
	cmp	ecx, 7
	je	SHORT $LN24@dlmallinfo

; 2801 :           size_t sz = chunksize(q);

	mov	esi, ecx

; 2802 :           sum += sz;
; 2803 :           if (!cinuse(q)) {

	mov	edx, ecx

; 2804 :             mfree += sz;
; 2805 :             ++nfree;
; 2806 :           }
; 2807 :           q = next_chunk(q);

	and	ecx, -4					; fffffffcH
	and	esi, -4					; fffffffcH
	add	DWORD PTR _sum$1$[esp+72], esi
	add	eax, ecx
	mov	ecx, DWORD PTR _nfree$1$[esp+72]
	inc	ecx
	and	edx, 2
	cmovne	ecx, DWORD PTR _nfree$1$[esp+72]
	add	esi, DWORD PTR _mfree$1$[esp+72]
	test	edx, 2
	mov	edx, DWORD PTR __gm_+24
	cmovne	esi, DWORD PTR _mfree$1$[esp+72]
	mov	DWORD PTR _nfree$1$[esp+72], ecx
	mov	DWORD PTR _mfree$1$[esp+72], esi
	cmp	eax, edi
	jae	SHORT $LL6@dlmallinfo
$LN24@dlmallinfo:
	mov	ebx, DWORD PTR _s$1$[esp+72]
$LN7@dlmallinfo:

; 2808 :         }
; 2809 :         s = s->next;

	mov	ebx, DWORD PTR [ebx+8]
	mov	DWORD PTR _s$1$[esp+72], ebx
	test	ebx, ebx
	jne	SHORT $LL4@dlmallinfo

; 2810 :       }
; 2811 : 
; 2812 :       nm.arena    = sum;
; 2813 :       nm.ordblks  = nfree;

	mov	eax, DWORD PTR _nfree$1$[esp+72]

; 2814 :       nm.hblkhd   = m->footprint - sum;

	mov	ecx, DWORD PTR __gm_+428
	mov	edi, DWORD PTR _sum$1$[esp+72]
	mov	DWORD PTR $T1[esp+76], eax
	mov	eax, ecx
	sub	eax, edi
	mov	DWORD PTR $T1[esp+72], edi
	mov	DWORD PTR $T1[esp+88], eax

; 2815 :       nm.usmblks  = m->max_footprint;
; 2816 :       nm.uordblks = m->footprint - mfree;

	sub	ecx, esi
	mov	eax, DWORD PTR __gm_+432
	mov	DWORD PTR $T1[esp+92], eax

; 2817 :       nm.fordblks = mfree;
; 2818 :       nm.keepcost = m->topsize;

	mov	eax, DWORD PTR __gm_+12
	mov	DWORD PTR $T1[esp+100], ecx
	mov	DWORD PTR $T1[esp+104], esi
	mov	DWORD PTR $T1[esp+108], eax
$LN9@dlmallinfo:

; 4344 :   return internal_mallinfo(gm);

	mov	eax, DWORD PTR $T2[ebp]
	lea	esi, DWORD PTR $T1[esp+72]
	mov	ecx, 10					; 0000000aH
	mov	edi, eax
	rep movsd

; 4345 : }

	pop	edi
	pop	esi
	pop	ebx
	mov	esp, ebp
	pop	ebp
	ret	0
_dlmallinfo ENDP
_TEXT	ENDS
END
